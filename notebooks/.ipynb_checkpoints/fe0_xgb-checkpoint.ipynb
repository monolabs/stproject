{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../src/stproject')\n",
    "from utils import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_stliq has length: 276\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>molecule</th>\n",
       "      <th>smiles</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>mol_formula</th>\n",
       "      <th>cas</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pentane</td>\n",
       "      <td>CCCCC</td>\n",
       "      <td>15.5</td>\n",
       "      <td>C5H12</td>\n",
       "      <td>109-66-0</td>\n",
       "      <td>0.62638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hexane</td>\n",
       "      <td>C(C)CCCC</td>\n",
       "      <td>18.0</td>\n",
       "      <td>C6H14</td>\n",
       "      <td>110-54-3</td>\n",
       "      <td>0.65940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heptane</td>\n",
       "      <td>CCCCCCC</td>\n",
       "      <td>19.8</td>\n",
       "      <td>C7H16</td>\n",
       "      <td>142-82-5</td>\n",
       "      <td>0.68420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Octane</td>\n",
       "      <td>CCCCCCCC</td>\n",
       "      <td>21.1</td>\n",
       "      <td>C8H18</td>\n",
       "      <td>111-65-9</td>\n",
       "      <td>0.70310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Nonane</td>\n",
       "      <td>CCCCCCCCC</td>\n",
       "      <td>22.4</td>\n",
       "      <td>C9H20</td>\n",
       "      <td>111-84-2</td>\n",
       "      <td>0.71760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_id molecule     smiles  measured_st mol_formula       cas  density\n",
       "1           1  Pentane      CCCCC         15.5       C5H12  109-66-0  0.62638\n",
       "2           2   Hexane   C(C)CCCC         18.0       C6H14  110-54-3  0.65940\n",
       "3           3  Heptane    CCCCCCC         19.8       C7H16  142-82-5  0.68420\n",
       "4           4   Octane   CCCCCCCC         21.1       C8H18  111-65-9  0.70310\n",
       "5           5   Nonane  CCCCCCCCC         22.4       C9H20  111-84-2  0.71760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_raw has length: 268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>C=C</th>\n",
       "      <th>C#C</th>\n",
       "      <th>Ar</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>...</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>M</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>molecule</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.151</td>\n",
       "      <td>15.5</td>\n",
       "      <td>Pentane</td>\n",
       "      <td>0.62638</td>\n",
       "      <td>115.187267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.178</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Hexane</td>\n",
       "      <td>0.65940</td>\n",
       "      <td>130.691538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.205</td>\n",
       "      <td>19.8</td>\n",
       "      <td>Heptane</td>\n",
       "      <td>0.68420</td>\n",
       "      <td>146.455715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.232</td>\n",
       "      <td>21.1</td>\n",
       "      <td>Octane</td>\n",
       "      <td>0.70310</td>\n",
       "      <td>162.469066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.259</td>\n",
       "      <td>22.4</td>\n",
       "      <td>Nonane</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>178.733278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C     H  C=C  C#C   Ar  O-alc  O-eth  O-ald  O-ket  O-acid  ...   R4  \\\n",
       "1  5.0  12.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "2  6.0  14.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "3  7.0  16.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "4  8.0  18.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "5  9.0  20.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "\n",
       "    R5   R6   R7   R8        M  measured_st  molecule  density          mv  \n",
       "1  0.0  0.0  0.0  0.0   72.151         15.5   Pentane  0.62638  115.187267  \n",
       "2  0.0  0.0  0.0  0.0   86.178         18.0    Hexane  0.65940  130.691538  \n",
       "3  0.0  0.0  0.0  0.0  100.205         19.8   Heptane  0.68420  146.455715  \n",
       "4  0.0  0.0  0.0  0.0  114.232         21.1    Octane  0.70310  162.469066  \n",
       "5  0.0  0.0  0.0  0.0  128.259         22.4    Nonane  0.71760  178.733278  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stliq = pd.read_csv('../data/df_stliq_clean.csv', index_col=0)\n",
    "df_fe0 = pd.read_csv('../data/df_fe0.csv', index_col=0)\n",
    "df_fe0['mv'] = df_fe0['M'] / df_fe0['density']\n",
    "\n",
    "print(f\"df_stliq has length: {len(df_stliq)}\")\n",
    "display(df_stliq.head())\n",
    "print(f\"df_raw has length: {len(df_fe0)}\")\n",
    "display(df_fe0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fe0 has length: 263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ar</th>\n",
       "      <th>C</th>\n",
       "      <th>C=C</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ester</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>72.151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62638</td>\n",
       "      <td>115.187267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>86.178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65940</td>\n",
       "      <td>130.691538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68420</td>\n",
       "      <td>146.455715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>114.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70310</td>\n",
       "      <td>162.469066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>178.733278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ar    C  C=C     H        M  O-acid  O-alc  O-ald  O-ester  O-eth  O-ket  \\\n",
       "1  0.0  5.0  0.0  12.0   72.151     0.0    0.0    0.0      0.0    0.0    0.0   \n",
       "2  0.0  6.0  0.0  14.0   86.178     0.0    0.0    0.0      0.0    0.0    0.0   \n",
       "3  0.0  7.0  0.0  16.0  100.205     0.0    0.0    0.0      0.0    0.0    0.0   \n",
       "4  0.0  8.0  0.0  18.0  114.232     0.0    0.0    0.0      0.0    0.0    0.0   \n",
       "5  0.0  9.0  0.0  20.0  128.259     0.0    0.0    0.0      0.0    0.0    0.0   \n",
       "\n",
       "    R5   R6  density          mv  \n",
       "1  0.0  0.0  0.62638  115.187267  \n",
       "2  0.0  0.0  0.65940  130.691538  \n",
       "3  0.0  0.0  0.68420  146.455715  \n",
       "4  0.0  0.0  0.70310  162.469066  \n",
       "5  0.0  0.0  0.71760  178.733278  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exclude features globally\n",
    "features_excluded = ['C#C', 'R3', 'R4', 'R7', 'R8']\n",
    "df_fe0_clean = df_fe0.loc[df_fe0[features_excluded].sum(axis=1) == 0, df_fe0.columns.difference(features_excluded)]\n",
    "\n",
    "X_fe0 = df_fe0_clean[df_fe0_clean.columns.difference(['molecule', 'measured_st'])]\n",
    "y_fe0 = df_fe0_clean['measured_st']\n",
    "\n",
    "print(f\"X_fe0 has length: {len(X_fe0)}\")\n",
    "display(X_fe0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x28bcea66608>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x2880 with 272 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df_fe0_clean[df_fe0_clean.columns.difference(['molecule'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fe0_train has length: 240\n",
      "X_fe0_test has length: 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ar</th>\n",
       "      <th>C</th>\n",
       "      <th>C=C</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ester</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>114.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7160</td>\n",
       "      <td>159.541899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>180.468552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>112.216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7736</td>\n",
       "      <td>145.056877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>140.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>171.521154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>134.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8620</td>\n",
       "      <td>155.709977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ar     C  C=C     H        M  O-acid  O-alc  O-ald  O-ester  O-eth  \\\n",
       "18  0.0   8.0  0.0  18.0  114.232     0.0    0.0    0.0      0.0    0.0   \n",
       "23  0.0   9.0  0.0  20.0  128.259     0.0    0.0    0.0      0.0    0.0   \n",
       "30  0.0   8.0  0.0  16.0  112.216     0.0    0.0    0.0      0.0    0.0   \n",
       "38  0.0  10.0  0.0  20.0  140.270     0.0    0.0    0.0      0.0    0.0   \n",
       "59  1.0  10.0  0.0  14.0  134.222     0.0    0.0    0.0      0.0    0.0   \n",
       "\n",
       "    O-ket   R5   R6  density          mv  \n",
       "18    0.0  0.0  0.0   0.7160  159.541899  \n",
       "23    0.0  0.0  0.0   0.7107  180.468552  \n",
       "30    0.0  1.0  0.0   0.7736  145.056877  \n",
       "38    0.0  0.0  1.0   0.8178  171.521154  \n",
       "59    0.0  0.0  0.0   0.8620  155.709977  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting out test set\n",
    "# Test set is chosen according to literature (original_id in df_stliq contains 'Test')\n",
    "test_idx = df_stliq[df_stliq['original_id'].str.contains('Test')].index.tolist()\n",
    "X_fe0_train = X_fe0.loc[~X_fe0.index.isin(test_idx)]\n",
    "X_fe0_test = X_fe0.loc[test_idx]\n",
    "y_fe0_train = y_fe0.loc[~X_fe0.index.isin(test_idx)]\n",
    "y_fe0_test = y_fe0.loc[test_idx]\n",
    "\n",
    "print(f\"X_fe0_train has length: {len(X_fe0_train)}\")\n",
    "print(f\"X_fe0_test has length: {len(X_fe0_test)}\")\n",
    "display(X_fe0_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining space of optimization with BO\n",
    "space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "             'eta' : hp.quniform('eta', 0.01, 0.10, 0.02),\n",
    "             'max_depth' : hp.choice('max_depth', np.arange(1, 13, 1)),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'eval_metric': 'rmse',\n",
    "             'objective': 'reg:squarederror',\n",
    "             'nthread' : 6,\n",
    "             'silent' : 1,\n",
    "             'seed': 42\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fe0_xgb_f_ll\n",
    "\n",
    "XGB with full features, trained on liquids, tested on liquids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_fe0_xgb_f_l, params_fe0_xgb_f_l = run_xgb(X_fe0_train,\n",
    "#                                                 y_fe0_train,\n",
    "#                                                 space,\n",
    "#                                                 k=5,\n",
    "#                                                 max_evals=250,\n",
    "#                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/models_fe0_xgb_f_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(models_fe0_xgb_f_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('../models/params_fe0_xgb_f_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(params_fe0_xgb_f_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# post-training (pickle of models exists)\n",
    "with open('../models/models_fe0_xgb_f_l.pickle', 'rb') as handle:\n",
    "    models_fe0_xgb_f_l = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = 1.8094532055482424, mae = 1.1418776968251116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>C=C</th>\n",
       "      <th>C#C</th>\n",
       "      <th>Ar</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>...</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>M</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>molecule</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.095</td>\n",
       "      <td>45.2</td>\n",
       "      <td>Trimethylene glycol</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>72.271821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.242</td>\n",
       "      <td>24.1</td>\n",
       "      <td>2,6-Dimethyl-4-heptanone</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>176.435128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.214</td>\n",
       "      <td>23.8</td>\n",
       "      <td>3-Methylbutanoic acid propyl ester</td>\n",
       "      <td>0.8620</td>\n",
       "      <td>167.301624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.133</td>\n",
       "      <td>21.8</td>\n",
       "      <td>Isopropyl acetate</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>117.151870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.122</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2-Ethoxyethanol</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>96.801289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C     H  C=C  C#C   Ar  O-alc  O-eth  O-ald  O-ket  O-acid  ...   R4  \\\n",
       "100  3.0   8.0  0.0  0.0  0.0    2.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "160  9.0  18.0  0.0  0.0  0.0    0.0    0.0    0.0    1.0     0.0  ...  0.0   \n",
       "223  8.0  16.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "193  5.0  10.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "103  4.0  10.0  0.0  0.0  0.0    1.0    1.0    0.0    0.0     0.0  ...  0.0   \n",
       "\n",
       "      R5   R6   R7   R8        M  measured_st  \\\n",
       "100  0.0  0.0  0.0  0.0   76.095         45.2   \n",
       "160  0.0  0.0  0.0  0.0  142.242         24.1   \n",
       "223  0.0  0.0  0.0  0.0  144.214         23.8   \n",
       "193  0.0  0.0  0.0  0.0  102.133         21.8   \n",
       "103  0.0  0.0  0.0  0.0   90.122         28.6   \n",
       "\n",
       "                               molecule  density          mv  \n",
       "100                 Trimethylene glycol   1.0529   72.271821  \n",
       "160            2,6-Dimethyl-4-heptanone   0.8062  176.435128  \n",
       "223  3-Methylbutanoic acid propyl ester   0.8620  167.301624  \n",
       "193                   Isopropyl acetate   0.8718  117.151870  \n",
       "103                     2-Ethoxyethanol   0.9310   96.801289  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_fe0_xgb_f_ll, mae_fe0_xgb_f_ll, i_out_fe0_xgb_f_ll = evaluate_xgb_models(models_fe0_xgb_f_l,\n",
    "                        X_fe0_test, \n",
    "                        y_fe0_test, \n",
    "                        weights=None,\n",
    "                        num_outliers=5, \n",
    "                        title='fe0_xgb_f_ll\\nfull features, train: liquid, test: liquid',\n",
    "                        x_label='predicted surface tension',\n",
    "                        y_label='measured surface tension',\n",
    "                        with_line=True)\n",
    "print(f\"rmse = {rmse_fe0_xgb_f_ll}, mae = {mae_fe0_xgb_f_ll}\")\n",
    "display(df_fe0.loc[i_out_fe0_xgb_f_ll])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density</th>\n",
       "      <th>C</th>\n",
       "      <th>M</th>\n",
       "      <th>H</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>O-ester</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>Ar</th>\n",
       "      <th>mv</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>R6</th>\n",
       "      <th>C=C</th>\n",
       "      <th>R5</th>\n",
       "      <th>O-ald</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.655265</td>\n",
       "      <td>21.467767</td>\n",
       "      <td>15.93471</td>\n",
       "      <td>5.190725</td>\n",
       "      <td>20.693325</td>\n",
       "      <td>20.406705</td>\n",
       "      <td>30.90071</td>\n",
       "      <td>42.262742</td>\n",
       "      <td>4.91996</td>\n",
       "      <td>9.240658</td>\n",
       "      <td>15.84418</td>\n",
       "      <td>6.88916</td>\n",
       "      <td>6.25049</td>\n",
       "      <td>6.326815</td>\n",
       "      <td>2.326859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     density          C         M         H     O-acid    O-ester     O-alc  \\\n",
       "0  75.655265  21.467767  15.93471  5.190725  20.693325  20.406705  30.90071   \n",
       "\n",
       "          Ar       mv     O-eth     O-ket       R6      C=C        R5  \\\n",
       "0  42.262742  4.91996  9.240658  15.84418  6.88916  6.25049  6.326815   \n",
       "\n",
       "      O-ald  \n",
       "0  2.326859  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28bfee0d248>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting feature importances\n",
    "fi_fe0_xgb_f_l = pd.DataFrame(models_fe0_xgb_f_l[1].get_score(importance_type='gain'), index=[0])\n",
    "display(fi_fe0_xgb_f_l)\n",
    "sns.barplot(x=fi_fe0_xgb_f_l.loc[0], y=fi_fe0_xgb_f_l.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fe0_xgb_M_ll\n",
    "\n",
    "XGB with M only (excluding density and molar volume), trained on liquids, tested on liquids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_fe0_xgb_M_l, params_fe0_xgb_M_l = run_xgb(X_fe0_train[X_fe0_train.columns.difference(['density', 'mv'])],\n",
    "#                                                 y_fe0_train,\n",
    "#                                                 space,\n",
    "#                                                 k=5,\n",
    "#                                                 max_evals=250,\n",
    "#                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/models_fe0_xgb_M_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(models_fe0_xgb_M_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('../models/params_fe0_xgb_M_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(params_fe0_xgb_M_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# post-training (pickle of models exists)\n",
    "with open('../models/models_fe0_xgb_M_l.pickle', 'rb') as handle:\n",
    "    models_fe0_xgb_M_l = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = 2.51777847517272, mae = 1.7367897862973427\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>C=C</th>\n",
       "      <th>C#C</th>\n",
       "      <th>Ar</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>...</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>M</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>molecule</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.095</td>\n",
       "      <td>45.2</td>\n",
       "      <td>Trimethylene glycol</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>72.271821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.242</td>\n",
       "      <td>24.1</td>\n",
       "      <td>2,6-Dimethyl-4-heptanone</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>176.435128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.124</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Benzaldehyde</td>\n",
       "      <td>1.0470</td>\n",
       "      <td>101.360076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.133</td>\n",
       "      <td>21.8</td>\n",
       "      <td>Isopropyl acetate</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>117.151870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.177</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4-Methyl-2-pentanol</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>126.534985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C     H  C=C  C#C   Ar  O-alc  O-eth  O-ald  O-ket  O-acid  ...   R4  \\\n",
       "100  3.0   8.0  0.0  0.0  0.0    2.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "160  9.0  18.0  0.0  0.0  0.0    0.0    0.0    0.0    1.0     0.0  ...  0.0   \n",
       "152  7.0   6.0  0.0  0.0  1.0    0.0    0.0    1.0    0.0     0.0  ...  0.0   \n",
       "193  5.0  10.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "81   6.0  14.0  0.0  0.0  0.0    1.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "\n",
       "      R5   R6   R7   R8        M  measured_st                  molecule  \\\n",
       "100  0.0  0.0  0.0  0.0   76.095         45.2       Trimethylene glycol   \n",
       "160  0.0  0.0  0.0  0.0  142.242         24.1  2,6-Dimethyl-4-heptanone   \n",
       "152  0.0  0.0  0.0  0.0  106.124         38.0              Benzaldehyde   \n",
       "193  0.0  0.0  0.0  0.0  102.133         21.8         Isopropyl acetate   \n",
       "81   0.0  0.0  0.0  0.0  102.177         22.6       4-Methyl-2-pentanol   \n",
       "\n",
       "     density          mv  \n",
       "100   1.0529   72.271821  \n",
       "160   0.8062  176.435128  \n",
       "152   1.0470  101.360076  \n",
       "193   0.8718  117.151870  \n",
       "81    0.8075  126.534985  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_fe0_xgb_M_ll, mae_fe0_xgb_M_ll, i_out_fe0_xgb_M_ll = evaluate_xgb_models(models_fe0_xgb_M_l,\n",
    "                        X_fe0_test[X_fe0_test.columns.difference(['density', 'mv'])], \n",
    "                        y_fe0_test, \n",
    "                        weights=None,\n",
    "                        num_outliers=5, \n",
    "                        title='fe0_xgb_M_ll\\n-density -mv, train: liquid, test: liquid',\n",
    "                        x_label='predicted surface tension',\n",
    "                        y_label='measured surface tension',\n",
    "                        with_line=True)\n",
    "print(f\"rmse = {rmse_fe0_xgb_M_ll}, mae = {mae_fe0_xgb_M_ll}\")\n",
    "display(df_fe0.loc[i_out_fe0_xgb_M_ll])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fe0_xgb_d_ll\n",
    "\n",
    "XGB with density only (excluding molar volume and M), trained on liquids, tested on liquids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_fe0_xgb_d_l, params_fe0_xgb_d_l = run_xgb(X_fe0_train[X_fe0_train.columns.difference(['M', 'mv'])],\n",
    "#                                                 y_fe0_train,\n",
    "#                                                 space,\n",
    "#                                                 k=5,\n",
    "#                                                 max_evals=250,\n",
    "#                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/models_fe0_xgb_d_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(models_fe0_xgb_d_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('../models/params_fe0_xgb_d_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(params_fe0_xgb_d_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# post-training (pickle of models exists)\n",
    "with open('../models/models_fe0_xgb_d_l.pickle', 'rb') as handle:\n",
    "    models_fe0_xgb_d_l = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = 1.709571355272147, mae = 1.1298425923223079\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>C=C</th>\n",
       "      <th>C#C</th>\n",
       "      <th>Ar</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>...</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>M</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>molecule</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.095</td>\n",
       "      <td>45.2</td>\n",
       "      <td>Trimethylene glycol</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>72.271821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.242</td>\n",
       "      <td>24.1</td>\n",
       "      <td>2,6-Dimethyl-4-heptanone</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>176.435128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.124</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Benzaldehyde</td>\n",
       "      <td>1.0470</td>\n",
       "      <td>101.360076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.133</td>\n",
       "      <td>21.8</td>\n",
       "      <td>Isopropyl acetate</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>117.151870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.214</td>\n",
       "      <td>23.8</td>\n",
       "      <td>3-Methylbutanoic acid propyl ester</td>\n",
       "      <td>0.8620</td>\n",
       "      <td>167.301624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C     H  C=C  C#C   Ar  O-alc  O-eth  O-ald  O-ket  O-acid  ...   R4  \\\n",
       "100  3.0   8.0  0.0  0.0  0.0    2.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "160  9.0  18.0  0.0  0.0  0.0    0.0    0.0    0.0    1.0     0.0  ...  0.0   \n",
       "152  7.0   6.0  0.0  0.0  1.0    0.0    0.0    1.0    0.0     0.0  ...  0.0   \n",
       "193  5.0  10.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "223  8.0  16.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "\n",
       "      R5   R6   R7   R8        M  measured_st  \\\n",
       "100  0.0  0.0  0.0  0.0   76.095         45.2   \n",
       "160  0.0  0.0  0.0  0.0  142.242         24.1   \n",
       "152  0.0  0.0  0.0  0.0  106.124         38.0   \n",
       "193  0.0  0.0  0.0  0.0  102.133         21.8   \n",
       "223  0.0  0.0  0.0  0.0  144.214         23.8   \n",
       "\n",
       "                               molecule  density          mv  \n",
       "100                 Trimethylene glycol   1.0529   72.271821  \n",
       "160            2,6-Dimethyl-4-heptanone   0.8062  176.435128  \n",
       "152                        Benzaldehyde   1.0470  101.360076  \n",
       "193                   Isopropyl acetate   0.8718  117.151870  \n",
       "223  3-Methylbutanoic acid propyl ester   0.8620  167.301624  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_fe0_xgb_d_ll, mae_fe0_xgb_d_ll, i_out_fe0_xgb_d_ll = evaluate_xgb_models(models_fe0_xgb_d_l,\n",
    "                        X_fe0_test[X_fe0_test.columns.difference(['M', 'mv'])], \n",
    "                        y_fe0_test, \n",
    "                        weights=None,\n",
    "                        num_outliers=5, \n",
    "                        title='fe0_xgb_d_ll\\n-M -mv, train: liquid, test: liquid',\n",
    "                        x_label='predicted surface tension',\n",
    "                        y_label='measured surface tension',\n",
    "                        with_line=True)\n",
    "print(f\"rmse = {rmse_fe0_xgb_d_ll}, mae = {mae_fe0_xgb_d_ll}\")\n",
    "display(df_fe0.loc[i_out_fe0_xgb_d_ll])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fe0_xgb_fr_ll\n",
    "XGB with fragments only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 648.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.864801184555641                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 388.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.958780106386137                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 338.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.2658157267008576                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 870.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.1645559819087645                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 373.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9634229493220343                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 696.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.9327539723963274                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 957.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.0631134753322944                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 485.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.1219200949669292                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 383.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.181328778639146                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 395.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.221728424817476                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 221.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.144911950877679                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 116.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.535123535941689                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 935.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.993674230384678                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 215.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.0136610785560665                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 314.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.802912551387576                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 283.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.2194439947237385                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 900.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.2138509426191497                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 460.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9197969777820854                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 594.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.8103815995061043                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 596.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.201695317609181                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 757.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.545296940851506                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 533.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.809610022297335                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 494.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.697791916156954                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 111.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.585451146524487                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 202.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.015408447764028                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 478.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.4878544760726338                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 303.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.8302154917398226                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 701.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.8870331849579975                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 540.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.897607069701391                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 812.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.7699130399913248                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 754.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.600887223714401                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 815.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6503683693173867                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 639.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.57437210237937                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.137609409731283                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 835.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5678143470542016                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 796.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.713557679488913                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 862.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.34811032247748                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 990.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.91279085873937                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 844.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.6491630889517372                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 687.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.905519132699748                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 864.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.978584719973615                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 932.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.9367263838510826                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 747.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.9736232899763553                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 965.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.851325168621855                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 845.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.973563943313549                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 909.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.929024976451504                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 634.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.0604752222124065                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 427.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.111694923802907                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 670.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7607774114842605                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 723.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.986131862860159                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 783.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9133755292019643                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 889.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.1745933981997134                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 594.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.0105774181577036                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 963.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.534324788365981                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 966.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.4386303134037894                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.9417146099857594                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 924.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9466879970842927                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 174.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.376359152226396                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 348.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.4002655577849774                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 263.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.0807921963325646                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 574.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.650953122832217                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 722.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7238823054873627                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 513.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.5269763293592944                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 510.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.7198229695772187                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 432.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7876321998823217                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 402.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6030133688918626                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 619.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7889173202094355                                                                                              \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 561.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5464813640640536                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 355.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.462769280644444                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 454.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.581590561445941                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 151.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.4164945424943465                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 561.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.68308951304586                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 319.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.878337350522576                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 514.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7129867032954866                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 248.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.54728550852993                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 378.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.8138404882735286                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 413.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.9907142922403                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 661.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.5390324401552027                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 533.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.775932437841812                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 477.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.817125404319146                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 292.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.4642425480636887                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 326.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7732036759609917                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 615.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.949337891019758                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 578.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.9699954765661034                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 773.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7239695040510292                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 448.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.5221798874516432                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 724.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.948461852657744                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 552.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.678612569734851                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 363.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.1004499085473958                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 235.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.95825283882373                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 686.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.778886667326078                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 198.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.963214230468575                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 140.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7379823688650724                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 499.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.966055068585043                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 267.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.824266754592042                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 808.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.7196418550928727                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 884.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.1829710426573627                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 394.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7983018729459186                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 100.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.2273949274303164                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 472.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.4608656600911067                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 532.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.8668105070384686                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 614.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8246981269498814                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 951.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.8033714854893166                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 335.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.9935209607102307                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 648.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.77321785422965                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 738.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7585555968817945                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 430.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.0942565916300224                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 702.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.503553313168247                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 516.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.689075177999267                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 679.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.790729624390861                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 766.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.823839377747587                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 595.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.982107998972756                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 575.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.5754941769769637                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.890698870013001                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 982.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.5156688738422135                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 652.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.7654986902963574                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 705.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6942967743166215                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 414.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.755904274198033                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 796.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.9522881425399503                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 916.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.774288004691103                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 375.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.891551764516318                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 631.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.699140395355193                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 296.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.69388717712575                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 451.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.901840426452838                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 871.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7741359173024263                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 484.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.039687309614448                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 184.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.2174826881050724                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 560.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.5238453962861036                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 132.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.0343896099742285                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 278.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.9811870607422604                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 949.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.8747653986862542                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 240.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.456065517986111                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 499.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.493877443362143                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 313.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8173868059129323                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 742.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.899636851615551                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 343.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.6650391306023384                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 542.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.8993702506353607                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 781.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.1063837368537883                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 225.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.6458930062798345                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 842.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.8117773273638016                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 464.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7331622375719355                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 661.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8025108326392214                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 441.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.82554139081866                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 612.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.80894351374975                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 901.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.690857801367538                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 987.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.1296201215252193                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7427673771872034                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 877.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5664533058179115                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 972.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5203691566872144                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 996.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.51894210002525                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 939.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.930939380696764                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 975.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.6129653665868515                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 854.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.4396044206869245                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 809.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.743938265353715                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 900.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.914490210768073                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 918.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.480455718306975                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 717.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.791465823023631                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 514.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.909794847007711                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 965.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.501580399163531                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 760.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.722657609633532                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 402.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.853593480623898                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 581.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.664646727036452                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 361.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.537061802059046                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 627.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.801421843830506                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 929.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.664142817400669                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 531.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.5630405486353642                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.0102597926767807                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.709530270224909                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 680.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.69983815082255                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 820.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.8245622486029007                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 166.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.938482389232268                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 796.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.6594175600152377                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 493.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.0907822936226763                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 867.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7082353105907426                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 604.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.749361818772911                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 555.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.547675994673305                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 636.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7755482082527285                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 729.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.551804411901797                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 895.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.799227994982633                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 952.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.930635453713734                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 697.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.4976807343893173                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 695.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.635137972155177                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 780.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.10170776306764                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 749.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.9921154526229556                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 844.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7521987790607385                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 590.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.838934090297959                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 996.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6600117763153324                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 663.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.5999578836036887                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 912.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.839268657548436                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 932.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.8538579685295455                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 471.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.773395482696997                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 888.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7182595592044962                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 966.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8344675002561743                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 645.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.427854724891231                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 858.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.713311037365328                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 711.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8183249608285648                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 820.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.560297972042                                                                                                  \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 943.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.595631215784984                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 525.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.863102727552211                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 571.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.688579967217266                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 766.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.788998666810123                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.4602831449677223                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 795.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.8048859763295977                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 452.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.663232793619713                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 982.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.083906783353277                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 879.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.4675442705214916                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 677.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.977024354762276                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 503.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.811647404836435                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 207.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.8172089219459298                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 402.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.858736376443188                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 543.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.6426068692773446                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 730.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7016141685677093                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 331.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.8714463628649614                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 482.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.4296722725371582                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 609.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.881363248879214                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 697.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.3442580567033113                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 911.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.0501579989572667                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 844.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.7734470785722722                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 432.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.71615506559117                                                                                                \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 958.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.536951954145762                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 367.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.794651536477294                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 754.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.748903198742418                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 800.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.0244173316256626                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 261.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.8388197980487377                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 927.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.964064638815861                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 624.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.732714855864445                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 827.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.433957668686227                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 591.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.662822397902353                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 308.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.388514295632033                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 783.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7701233670840213                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 865.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.8243835863955495                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 654.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.617715947674793                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 567.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6207015562310505                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 975.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.7187911499900426                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 525.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.077893157669569                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 461.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.492886082095581                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 349.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.823113270220369                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8844099875124                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 416.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.760740293010019                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 892.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.9661105121398954                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 718.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.902035159914048                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 550.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.636420679558193                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 745.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6795252599152657                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 668.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.5084143341551512                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 638.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7496012692382226                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 492.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7738857325837185                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 286.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.8792556395880804                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 689.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.0017155170577343                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 953.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.840470582736771                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 772.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.720601821326777                                                                                               \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [03:05<00:00,  1.35trial/s, best loss: 2.4976807343893173]\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 261.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.798519698802212                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 124.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.5125618296578742                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 912.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.26681546073976                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 287.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.24957969984877                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 332.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.002190963400008                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 799.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.438906572447432                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 604.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.362151108574849                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 310.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.6560920220378734                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 886.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.522921010897198                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 921.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.3793726993252164                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 654.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.4227387400243687                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 753.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.4918568802954537                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 731.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.66962942189404                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 139.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.984633845228328                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 953.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.3547910509944394                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 641.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.08513456176878                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 962.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.40839542144663                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 654.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.5021978182028968                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 437.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.3614352880774963                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 268.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.7898307956310022                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 489.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.4193918613249807                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 401.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.2923456978973684                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 538.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.203339983527642                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 396.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.0794383409667754                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 193.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.2395746025573944                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 359.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.3639295189502594                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 202.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.2510865174676207                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 484.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.146389770822609                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 339.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3146828224421068                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 209.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.542206426399128                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 393.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.1238138617727214                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 110.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.245569080992021                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 553.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.145291362888557                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 452.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.380925011923069                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 239.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.23740978927319                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 149.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.9751860318749572                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 314.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.689983185259612                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 530.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.318604751592012                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 395.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.361909218851999                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 583.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.3158260966272244                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 284.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.065656229814998                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 277.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.1747550226298626                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 174.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.14801335884389                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 101.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.179967480447418                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 227.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3424878603993404                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 320.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.6295296786074878                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 684.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.4867146063968466                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 823.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.151801263465948                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 252.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.197598326548894                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 154.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.2736193075701627                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 359.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.5219547332979473                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 433.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.1165742068827087                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 506.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.4487216517685226                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 306.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2627098026029953                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 453.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.2405569962620784                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 281.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.400321224800556                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 620.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.4516140326343487                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 728.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.351699288656327                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 360.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.098886497708813                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 477.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.2792955956380867                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 568.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.4652896250537593                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 833.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.141186234274239                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 414.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.3117512042313257                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 168.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.3659972983989097                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 114.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.39009012373365                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 378.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.19161993995593                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 338.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.304067876178203                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 521.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.05791802841824                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 511.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.1129985756037604                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 689.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.3609745324191262                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 616.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.086881684052219                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 776.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.32976751755006                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 590.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.364544688728804                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 224.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 1.9717699735941572                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 213.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.4280338651155478                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 880.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.402486787197884                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 993.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.099793900507506                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 242.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.354435915035854                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 134.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.4740768774655844                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 469.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.1433536509660986                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 420.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.276659240300903                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 529.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.109295404734151                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 334.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.2978440069969106                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 261.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.3438909724714887                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 302.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.2550186688676273                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 185.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.039848135695417                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 195.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.3384431502879544                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 167.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.294537926176394                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 225.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3637384984797167                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 120.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.0969275839086166                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 187.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.243050240624686                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 151.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 1.9756318886546949                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 373.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.3073162916530876                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 145.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3059280157005384                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 291.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.512812680874322                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 236.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.2878380816794537                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 100.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.511468664658496                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 263.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.4857956880061556                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 131.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.549373795546145                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 452.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.315033508404463                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 215.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.1329767700942166                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 323.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.0593467201406908                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 355.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.3882764290834944                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 492.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.316054470958033                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 556.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.4929262657828706                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 158.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.0504166659062153                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.3500065744698646                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 294.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.1643508855885747                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 437.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.320413793059783                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 381.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.365395446863295                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 250.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.5352096226599943                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 279.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.0868260863567456                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 645.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.3497831814860954                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 180.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.8015087619748558                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 206.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.2447936048938506                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 345.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.3362055970650726                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 319.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.5399922342155272                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 111.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.228074363896917                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 389.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.0832790633569305                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 714.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.3450266419335226                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 149.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.265432875379775                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 230.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.2853984938155096                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 103.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.239081719410984                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 274.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.3372037189667108                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 930.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.085795236203347                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 136.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.34101958058783                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 671.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.517073421562086                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 305.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.2786396738969095                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 433.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.1384462450241255                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 463.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.1046689010830324                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 589.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.4468726271584957                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 202.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.249379708718716                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 172.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.1335150598642287                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 252.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.000124209250355                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 495.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.33886261345519                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 1000.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.3431202848107753                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 774.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.2096316243124097                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 253.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.4794816721600186                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 365.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.003428386086704                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 126.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.006892739163636                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 221.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.74916984651205                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 340.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.042808748534164                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 873.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.351354579290195                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 159.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.20440874130629                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 267.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.0508971863297676                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 244.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.3829456224546393                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 189.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.4752875189006818                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 326.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.0313666413174425                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 404.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.3346873059973294                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 298.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.2905934491949993                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 420.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1545417753385134                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 219.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.056144557326872                                                                                               \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 288.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.343482649221927                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 101.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.0463345885402564                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 203.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.1113388923213807                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 140.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.3746207212049764                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 350.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.1363523994869835                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 381.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3096488666840522                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 164.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.1265895590154877                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 311.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.307256516846519                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 119.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6856602921411126                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 265.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.2196439880289573                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 232.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3392404560368707                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 180.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.354360765037138                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 555.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.1918112556998173                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 627.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.3235895819550607                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 442.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3753558531298706                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 242.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.4203326793822395                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 536.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.0844116038872236                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 512.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.186440640551779                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 100.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.0710893208961263                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 369.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.341870411302207                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 324.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.347890876401298                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 282.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.3517363722062914                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 480.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.0647724626491413                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 195.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.6272961461859055                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 396.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.5405463709998295                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 146.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.2491299333637813                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 213.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.3510889924743252                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 260.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.2795814084923576                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 343.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.548558734943809                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 574.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.566760725202629                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 306.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.120657682599291                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 118.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.250169887122171                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 176.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.3138474781162923                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 233.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.0695852574608864                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 461.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.4885854632639015                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 158.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.0671112494863615                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 278.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3988712199481617                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.501644505069238                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 364.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.3225768733219607                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 196.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 1.9545237163813833                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 118.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.648606884723855                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 133.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.5093486959359033                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 251.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.044190559834443                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 818.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.3352328350917864                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 199.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 1.9860727785140293                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 180.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.4111967569822186                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 204.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.005624444398842                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 104.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.6366112954766185                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 143.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.438492063845002                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 972.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.358208757241601                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 163.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.1091781955408724                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 226.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.245896911591933                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 292.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.085985507759407                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 191.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.2661592578392864                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 604.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.18592293064085                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 212.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.144753293608821                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 750.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.347621062643886                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 328.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.0596982506329935                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 706.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.217787759578292                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 103.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.4868662192964854                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 145.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.077990767211198                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 664.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.2285409139490344                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 119.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.7420174615045925                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 275.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.444546839456319                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 168.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3639063879715665                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 315.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.282757346363768                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 235.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.012180886164607                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3527306220896413                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 194.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.089243236602836                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 133.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.4181523667832527                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 349.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.3221285873519677                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 263.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.3337428972178125                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 296.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.045772767618696                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 847.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.036887591495433                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 101.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.322808568627669                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 154.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.39540788979553                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 215.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.0845680471091637                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 334.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.618438771950569                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 410.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 1.9917268668523211                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 252.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.361453257749723                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 190.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.2209130741403684                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 177.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.220067017741198                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 127.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.552964626168039                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 494.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.1340897485129307                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 235.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.2113925585715624                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 932.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.358878195669985                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 898.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.0874748210643976                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 313.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.3198367703195206                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 450.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.3573658114016824                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 277.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.2941761758541426                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 365.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.213533332867058                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 206.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.273827393612435                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 787.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.315330409414976                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 151.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.144421737438738                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 105.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.7082432232801774                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 433.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.3185358122215423                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 390.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.106179872437031                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 296.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1522645111430667                                                                                              \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [02:06<00:00,  1.98trial/s, best loss: 1.9545237163813833]\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 547.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.3741574446206446                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.4509639272065966                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 136.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.650084673043423                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 364.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.036286563273917                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 284.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.550661501671972                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.482671753273193                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 449.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.675088007046353                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 638.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.355566434083603                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 358.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.337853444048758                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 228.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.316663584035601                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 264.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.370672667646922                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 721.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.800369448902334                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 173.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.665610965096401                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 214.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6765542590033453                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 930.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.458238915698989                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 367.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.4105418535907743                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 597.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.516381265810256                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 662.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.287165196401939                                                                                               \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 266.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.242700866877507                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 628.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.282806909472495                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 803.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.2085142643030173                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 819.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.8350780214641125                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 903.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.492081337666065                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 764.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.1400936319708777                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 793.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.140600574733091                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.160583850250638                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 994.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.194376038222707                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 757.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.1541166950342805                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 508.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.386642839590927                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 982.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.1730806947449537                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 720.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1382290878384835                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 541.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.6561672606633064                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 703.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1508978860832157                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 877.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.927390868787827                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 472.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.2728106100885888                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 581.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.7399553991018912                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 702.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.1568781864857707                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 949.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8243698848969867                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 873.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.8432587807260634                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 757.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.00633339600489                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 675.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.379056433309082                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 442.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.295301820322404                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 853.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.544090111861382                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 767.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.2313424114808624                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 113.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.911020245569615                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 542.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.784166927141789                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 601.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.2501948356561527                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 412.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.117039577772809                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 318.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.3363657196470315                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 938.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.5107485431284937                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 643.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.189174753333916                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 736.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.5169384795278797                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 502.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.255239817545785                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 687.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.4680271842214405                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 570.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.248329397478769                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 782.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3492157662619144                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 912.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.8785521747733993                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 836.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.7393228583464833                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 625.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.3725778990072355                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 734.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.480064008978158                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 972.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.311841667444059                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 334.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.7215463411261576                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 805.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.1714876746468414                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 513.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.33108799780986                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 402.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.7882880284568143                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 885.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.140543256596201                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 879.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.11191545084397                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 855.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.140807984881907                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 657.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.116727863808811                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 646.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1178272709903028                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 646.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.1592677906741953                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 617.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.505248199210495                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 470.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.43197512236454                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 172.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.333104968779107                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 561.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.2201527536026875                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 667.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.1527042404920564                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 960.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2961043191574553                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 589.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.175986054826288                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 996.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.378873672982274                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 910.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.396990167399305                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 706.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.369896120411891                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 432.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.4947900851424087                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 482.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.1478379258281466                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 535.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.440970840756371                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 236.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.268601577645716                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 818.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.154985428784593                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 685.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.4832386075909745                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 606.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.3802200756809055                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 779.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.126154913551267                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 733.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.35151371027815                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 658.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.0486788163936605                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 841.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.10815970377079                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 847.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5997304501409215                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 930.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6162524265323492                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 888.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.093519876574974                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 897.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.5528062883908578                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 746.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.137471189253032                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 789.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.6579231543032815                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 821.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.126787237748145                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 866.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.502090624788774                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 981.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.118683926238376                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 713.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.1525893904805264                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 927.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.0091761730614945                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 764.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5733531472766003                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 945.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.80817674462129                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 797.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.076213903093907                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 812.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.2922699056163367                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 684.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3690827260931124                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 795.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.7184479119710505                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 892.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.254580503101466                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 721.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3726511234294643                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 524.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.675973200491618                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 746.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.1919684133602058                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 625.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.0052706710466013                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 559.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.666213626332448                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 495.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6157797005898384                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 453.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.41647103511881                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 584.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.637097134968213                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 376.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3608288965277224                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 321.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.300598476052174                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 617.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.6216849339861374                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 572.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.032217898043039                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 417.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.67886056918811                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 395.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.862781416116276                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 356.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.3107632115615124                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 463.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.151782597874059                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 573.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6062096942477506                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 630.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.7936082836230445                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 433.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.154780414197225                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 265.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7089780532352608                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 540.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.4189378664225085                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 666.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.110272715912808                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 519.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.589122226072139                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 484.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.7499864232887132                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 607.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.0944296307139574                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 159.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.709613021988617                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 643.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.45314932587775                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 205.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.9844271716663733                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 295.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.625824904763735                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 346.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3689908833656936                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 554.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6963552219439215                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 588.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.1753264365687177                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 699.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.588137775661159                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 668.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.414521614637182                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 506.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.5971964882716043                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 766.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.0951289142875127                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 691.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.125152072977416                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 652.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.0282967238706515                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 626.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.005314144909208                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 599.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 1.98835035583962                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 618.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.0192695104372906                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 627.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.6353922843298334                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 727.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.061978021246648                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 535.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.6446982909175087                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 603.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2627631090831977                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 446.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3944759011426004                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 490.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.262427703892299                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 552.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.6821800764676476                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 467.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.418355017827387                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 678.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.0313289093474087                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 711.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.6946260899375516                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 589.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.298996743785847                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 522.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.1123352945315785                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 744.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3894027877189283                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 387.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.483698272244471                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 419.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.6796557638306653                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 606.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.15174294617979                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 634.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3638614539119693                                                                                              \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 781.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.652204377012374                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 564.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3428970338157407                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 693.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.079632333146181                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 501.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.327049345512513                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 532.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.825271156669078                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 621.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.4824884722412945                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 656.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.084952444054906                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 105.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3959945843351482                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 718.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.795447750578958                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 577.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.0712772608061867                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 479.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3784949196478693                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 753.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3205948470700077                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 455.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.510035583413171                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.9195046258743496                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 675.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.338457950632634                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 637.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2438938380645688                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 547.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.752226194373387                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 597.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.4203951012150746                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 299.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.835266982066336                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 512.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.3242587607395264                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 856.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.8277452233969558                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 439.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.820411539551355                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 730.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.276874061779529                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 770.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1297602469651693                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 704.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.839668144218998                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 611.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.392417856785135                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 656.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.552937276075329                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 562.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.6670634717623414                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 363.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.375380287639952                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 582.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.114943783109656                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 808.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.033954216474139                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.5924982922657756                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 498.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.337346347710589                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 397.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.614528366572013                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 677.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.492941265445883                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 636.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.4542911197922654                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 527.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.030034100034864                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 620.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.180664516731843                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 470.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.696238718010047                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 692.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.6976750512152208                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 545.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.532158954991557                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 574.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.159387303405264                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 758.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.748022174274547                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 711.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.465219653421862                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 791.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.109281178100846                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 591.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.7508151923737496                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 648.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.101737141568268                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 323.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.7815779090906263                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 740.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.327965106027376                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 511.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.3720319986419414                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 487.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.157727274021176                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 666.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.7598612760883623                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 220.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7598675178047687                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 410.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.258108660530049                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 832.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.037395697269719                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 916.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1790797062115304                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 599.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.66147578698904                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 870.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.450119236295654                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 555.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.320819390245742                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 622.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.8801328019329073                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 730.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.3770149335886694                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 530.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.056023639843483                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 464.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.294194053130294                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 775.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.389973280196761                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 343.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.522898256399434                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 437.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6781852358646634                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 383.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.955070307941577                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 701.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.118551539580583                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 675.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.75508815985245                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 640.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.3748042114597974                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 820.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.144397366268312                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 560.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.389797069253385                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 751.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3447777570326767                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 136.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.6459175808476023                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 237.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.8962111261486796                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 617.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.346308919414039                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 572.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.542746149218112                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 486.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.496858064173843                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 449.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.286278092062387                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 719.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.4217738184325857                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 690.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.3571460714490486                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 964.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.8827455177746857                                                                                              \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [03:05<00:00,  1.35trial/s, best loss: 1.98835035583962]\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 303.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.1266187027559615                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 719.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.0018695975758725                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 354.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.2173778500565926                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 291.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.440158973950242                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 579.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.8567272691641934                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 961.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6741803165896423                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 153.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.1324824848495227                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 495.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.0842240111176493                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 264.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.9230985658167192                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 377.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.9263013936635227                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 870.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.1177710231225184                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 510.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.086924902675924                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 319.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.9703573649628643                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 139.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.9886057472001135                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 475.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.761980809727243                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 291.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.9396237602559836                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 374.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.1420918231869726                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 960.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.033067156605764                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 959.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.873773509432301                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 293.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.183577542512043                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 697.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7145715181073475                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 774.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.701854082707041                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 837.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7756639382374053                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 788.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.935149996370169                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 994.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6728138983754035                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 976.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.792976665736179                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 898.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9724012495268193                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 616.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.897909734051409                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 996.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.861693471879166                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 663.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.125537783110081                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 921.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9638315534304955                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 792.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.663480831380856                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 767.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.579882034466242                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 804.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.3686225459585892                                                                                              \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 734.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.5678363489465186                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 725.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.834936695187937                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 638.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.858736499228933                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 560.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.836667675620352                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 447.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.8736615679473587                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 734.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.881555245063478                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 601.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6352535279287026                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 685.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.87606738947385                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 854.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.830119459305931                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 538.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.977406156727831                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 216.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.885327428094326                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 752.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6257726799221537                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 913.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.864106029205171                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 654.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.131893144474729                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 446.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.1768960707622895                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 413.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.9744289164587365                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 823.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.7296864101372256                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 876.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.9568148274546724                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 509.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.3372813756490594                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 579.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.3392675238034646                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 705.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.058855560695999                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 761.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.577881624597882                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 940.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.8184529683149178                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 344.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.1479298007466703                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 618.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.0044955327008984                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 255.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.5071298252950642                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 541.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.988046830000705                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 816.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.8471224703271463                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 669.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.1594110910587223                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 849.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.716318782391031                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 894.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.8618821263002316                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 756.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.587041893890134                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 763.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.5399208003231184                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 736.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7865978056257834                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 705.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.5473844389907176                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 637.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.75794860888215                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 697.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.8898392596536353                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 481.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.77933445827352                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 598.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.639283499337194                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 563.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.8723762990401944                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 781.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.732261836980606                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 827.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.768146683910502                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 878.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.901238555140015                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 683.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.779538998576733                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 945.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.8815543605833063                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 796.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.542038748671005                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 990.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.751412469196837                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 799.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.5106111205133317                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 803.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.6899570982551912                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 856.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.701430211858186                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 919.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.654111811288422                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 959.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.955404130786385                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 644.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.724954359706393                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 901.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.9794405059992006                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 788.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.582078974343445                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 521.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.00193283279448                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 976.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.0584825752593083                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 720.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.0466149407359255                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 124.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.025738810943388                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 842.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.952970444818753                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 446.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.976684344738068                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 745.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9548530582863424                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 934.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.6896669165344926                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 869.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.808820235147378                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 810.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.796137177674483                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 616.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.4031116277306044                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 668.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.757408502120279                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 393.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.0623285256910378                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 773.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.55205106684144                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 890.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.7781087612496957                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 833.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.843698170365469                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 563.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.1494501781098756                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 590.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.175811359343848                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 717.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.5632482333825863                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 682.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.1331124443233804                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 624.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6741665174372833                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 864.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.9745601737323417                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 970.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.876066311468025                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 163.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.3584207522892706                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 793.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.6057980712891577                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 759.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.8596045817244415                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 500.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.711283156345774                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 414.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.860041281627674                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 319.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.3966176822257594                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 526.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.7685588381973814                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 580.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.561964311014989                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 992.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.9612014646877847                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 654.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.676931745841382                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 712.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.379894880701412                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 931.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6116991037631028                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 471.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.746193775516706                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 737.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.1993649675282434                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 908.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.996531202254319                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 695.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.799892331361754                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 952.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.9372184155528713                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 823.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.4761352567276274                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 826.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.692554993857383                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 878.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.802338661867553                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 773.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.8380814691087686                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 817.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6948999164983984                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 924.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6037333789496535                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 856.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.6756112112488295                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 610.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.7973314757603114                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 886.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.998756761018584                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 639.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6437027977776753                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 984.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.9868067377070897                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 550.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7128747127345973                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 1000.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.4336495622044048                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 227.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.2445611441184674                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.122474448573696                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 963.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.2925311055868036                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 906.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.4780773053917873                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 900.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.445757769536559                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 843.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6346427615923944                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 942.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.642140196467695                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 924.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.5907946731927587                                                                                              \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 906.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.4780773053917873                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.432502823501167                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 970.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6249974514967795                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 996.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6505318180727713                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 996.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.5143605639653495                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 951.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.596191157320283                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 882.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.563401470440912                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 865.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.619347926090491                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 978.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.541909927447143                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 932.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.5070862394585163                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 900.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.8203214575656834                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 350.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.870557298951034                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 839.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.552581854517819                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 959.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.849183983545467                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 806.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.536268070647994                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 997.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.776507959531766                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 946.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.042824919113451                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 976.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.7287937016991406                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 856.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.617873412479446                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 921.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.739666330904903                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 159.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.272951557220002                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 266.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.007027184209402                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 749.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.659212987166032                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 786.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.692653918113565                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 891.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.609233301296521                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 834.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.822461290534289                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.70038156368362                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 916.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.569167034027239                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 871.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.663191094068583                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 729.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.627036339432766                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 818.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.7069714108360725                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 971.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.915908229676758                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 188.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.9820884664299454                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 934.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.297903050391395                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 765.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.659708602000926                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 891.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.988978900494544                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 1000.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.5154182799986744                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 954.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.2447172190813895                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 848.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.5055531268697018                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 685.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.542982520332961                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 371.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.8416980607791764                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 665.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7386652753127536                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 910.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5672968455586562                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 430.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.902951955784235                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 874.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.728186613313168                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 797.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.8021370367023613                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 779.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.9630927994386083                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 316.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.228004027839058                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 940.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.715031476101511                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 974.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.75341009897832                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 479.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.6772458251592917                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 745.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8094143733044317                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 814.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.5909235710337195                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 714.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.529714558198846                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 827.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7817984094461905                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 1000.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.673884414097932                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 858.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.494143125206732                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 957.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.767314744245438                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 985.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.8104085597615236                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 899.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.6770566287559605                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 924.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.614422399817572                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 885.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.0059916571468235                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 574.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.929972538869245                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 944.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.5689102945114795                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 635.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.5783144333582126                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 698.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.199248511448194                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 835.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.549150361515857                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 774.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.2050146580987464                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 863.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6092670926474026                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 980.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.9332719754754994                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 915.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6780752673151893                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 728.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.654546199425445                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 531.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.7544649246478445                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 757.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.8931113113038807                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 959.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.4305876931572077                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 811.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.574445434136472                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 848.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.941479796271234                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 462.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.3569801425248063                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 107.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.7357973398911652                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 792.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.791476779585093                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 875.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.068710437681491                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 603.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.75093723482612                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 934.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.858671045772405                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 504.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.7635139431999                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 898.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.8001977672211558                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 668.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.6417081866494025                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 985.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.0991863304587195                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 961.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.614992261140244                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 924.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.540620415000526                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.796845232847656                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 823.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.730223653683179                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 279.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.29875089985564                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 885.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.907685417083518                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 907.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.9363806299438635                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 846.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7038039167257883                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 950.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.767497170101219                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.6228715720564426                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 747.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.7028424664556523                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 652.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.8139376225721278                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 799.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.0249283457483713                                                                                              \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [03:43<00:00,  1.12trial/s, best loss: 2.432502823501167]\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 230.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.111749908476447                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 326.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.1908863702181955                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 824.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.153945722122025                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 641.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.5889271340630966                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 442.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.04850933696565                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 237.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.341248682737925                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 841.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.1972117767667725                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 872.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.2395828648851825                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.3454350332761917                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 186.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.269629338392107                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 940.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.2878105725919844                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 714.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.072410019033013                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 530.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7823659962907588                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 886.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3659295626569645                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 786.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.371573768913117                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 874.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.39729301166559                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.3226015383518597                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 542.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.943117133530518                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 850.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.445604630619539                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 142.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.672993447578792                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 330.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.211662413672728                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 322.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3261862013152372                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 640.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2109021675907394                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 464.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.2889389606415973                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 637.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.189063762380487                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 759.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.959238186850603                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 298.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2797844374301004                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 118.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.391386580803365                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 1000.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.226764182684858                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 448.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.041471889755651                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 221.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.140161945195455                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 379.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.286169342124211                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 579.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.120994655662105                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 712.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.015363532162417                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 268.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.4155641554474245                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 481.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.043673850450693                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 942.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.05578124895248                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 379.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.1840673420101693                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 398.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.326159612737237                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 212.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.837878839437995                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 163.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.375586880841156                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 100.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.8994639365264656                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 510.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.673734678502443                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 416.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.975752498001672                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 600.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.5214091745529115                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 351.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.4425437622677437                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 251.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.287643659523461                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 498.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.428838231462648                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 300.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.1385228042862074                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 189.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.49701081202925                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 431.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.117978604565373                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 564.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.163330236280158                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 697.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.653274046022468                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 360.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.4334696598004006                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 143.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.7227827246298117                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 287.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.8673921731351575                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 531.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.227092753020419                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 684.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.4931999922472676                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 757.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.1784618987237                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 325.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3677592312003815                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 602.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.147855440999204                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 613.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.2244748446792157                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 668.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.050840597807948                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 794.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.096489525485425                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 742.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 1.9919281453800082                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 929.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.0396561724225677                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 929.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.258178807027762                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.154872304700186                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 896.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.0963651119899027                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 957.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.0737234227466375                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 969.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.0531592583984613                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 974.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.321942523853938                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 902.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.162934631748544                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 740.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.3870300099025963                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 855.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.564345442578193                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 807.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.4381725350149974                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 918.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3275112513461256                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 986.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.1195824115271193                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 779.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.318574942613792                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 871.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.1006673646802643                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 815.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.2477697622838666                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 728.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.3745544219796364                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 659.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.2683932986111706                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 841.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.375079588575005                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 958.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 1.9937572065292533                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 877.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.363298544908949                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 1000.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.5137851740021526                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 771.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3888998532098804                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 912.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3214154018384345                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 859.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.0438670837293933                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 942.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.087808857772134                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 747.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.2706944038156642                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 718.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.2146114749523838                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 628.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.216832608854439                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 803.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.217762865593379                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 828.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.255167146120899                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 695.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.0983029112966847                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 951.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.3220422436258286                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 925.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.4073982174693946                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 559.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.4055740748295515                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 583.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3154533700211104                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 890.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3414063026512353                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.1762150980453203                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 660.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.127674957496577                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 784.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.1765750243200896                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 984.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.2753406239417258                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 683.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.280342327462306                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 466.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.112882172276973                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 766.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.2630225843706717                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 841.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.472847395412271                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 866.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3550661578781495                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 964.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3958091427196204                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 734.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2527009904947684                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 514.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.3622287584202177                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 706.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3665105798292148                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 899.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.368991570003271                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 619.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.2832442537317585                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 644.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.205898966792571                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 823.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.1809508621420344                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 937.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.372130061841373                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 795.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.134516549138747                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 881.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.352994094545007                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 851.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1861629704402157                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 750.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.335854233171908                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 722.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.4098463791731706                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 573.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.5373985984167797                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 985.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.4125378988203234                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 914.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.0253025622717953                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 534.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.130516798644021                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 909.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2992748112891213                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 814.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.1392990617442873                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 686.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.3679285528668186                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 997.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.4431203545970104                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 596.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.447898055119663                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 952.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.1017411410217997                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 644.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.1959519603160036                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 840.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.1330385806381247                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 763.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.462229932641843                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 788.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.129385015381545                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 670.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.434035077324647                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 487.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.1636633602299398                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 547.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.509417411729011                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 420.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3855759003034813                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 887.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.31178972600532                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 970.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3775119573651615                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 912.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.0397805162644644                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 931.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.0460552211419563                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 862.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 1.9915305091915323                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 866.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.1101447011052477                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 808.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.040464537237714                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 955.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.082995989790006                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.128570309486169                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 894.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.1079104652840828                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 776.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.059737438113987                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 857.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.445756695965567                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 987.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.135122245418298                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 712.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.4406117508033454                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 923.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 1.9775231300421177                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 879.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3124585096067656                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 960.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.441955011727206                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 937.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.126242177123864                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 754.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.985599439933917                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 796.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3789169393085023                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 741.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.5188616397261865                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.347247024814269                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 848.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.9945191974950016                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 820.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.243493890450392                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 917.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 1.9813030804227296                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 871.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.9191794234594703                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 731.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.109024342745111                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 923.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.18896788116137                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 700.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.122727660691625                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 780.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.3541323224774438                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 903.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.1058324496845207                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 654.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2319028542563455                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 451.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.030759644085479                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 764.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.449227583906187                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 616.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.13918620446739                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.8472145957870523                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 975.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.346112476740039                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 887.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.958012153202942                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 672.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.383553920701362                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 808.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.380118925902595                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 942.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.3588583518998556                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 588.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.9896187523623046                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 511.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.072915652626207                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 843.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.074661291742351                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 631.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.1262746787962588                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 919.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.401649828372706                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 726.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.3529655482528526                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 395.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.362484883785596                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 863.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.0954946066390105                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 795.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.134023542044179                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 982.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.3674835036065636                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 746.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.2140468643381817                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 896.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.2086941294258855                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 693.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.007395864609815                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 948.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.4161385730307114                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 192.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.437067577464373                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 351.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.081479872953831                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 817.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.4011128181724164                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 997.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.0832525473947667                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 874.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.2650728916770646                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 772.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.15853741034874                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 850.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.31288581120486                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 930.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.11007043284771                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 973.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.152930284185248                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 713.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.093380889846341                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 785.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.2845086297834407                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 832.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.8043840138362817                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 567.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.2116472905516438                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 903.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.319128937549013                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 247.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.16179921903789                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 606.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.3987441789913806                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 685.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.0661533987522636                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 756.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.4395852089240884                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 800.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.4563022553612748                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 650.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 2.300878014992627                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 884.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.087346095791256                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.359418468784413                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 960.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.2560898077434643                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 863.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.1590234542520115                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 274.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.387036359397477                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 921.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.0900688068089766                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 740.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.0307392405185665                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 546.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.066229824575295                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 478.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.391793313172948                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 669.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.1943323287916208                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 821.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.384915768833827                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 913.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.0316377085627657                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 940.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.065117929171752                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 709.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.755834531253844                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 858.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.0620598827651846                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 972.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.3546115044141027                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 840.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.4040072140889897                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 766.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.313911092397923                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 2.332698128403096                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 890.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.2362651557168736                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 804.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.104951905774191                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 622.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.1447648001520454                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 128.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.104061034339732                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 782.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 2.208404643019818                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 317.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.2061437023599777                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 947.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 2.3258577469317343                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 719.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 2.3501257244145295                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 634.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 2.2430528746939307                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 517.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.00172994109913                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 826.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 2.469794293007972                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 879.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 2.401060915144252                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 909.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 2.114793047896584                                                                                               \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [03:39<00:00,  1.14trial/s, best loss: 1.9775231300421177]\n"
     ]
    }
   ],
   "source": [
    "models_fe0_xgb_fr_l, params_fe0_xgb_fr_l = run_xgb(X_fe0_train[X_fe0_train.columns.difference(['M', 'mv', 'density'])],\n",
    "                                                y_fe0_train,\n",
    "                                                space,\n",
    "                                                k=5,\n",
    "                                                max_evals=250,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/models_fe0_xgb_fr_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(models_fe0_xgb_fr_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('../models/params_fe0_xgb_fr_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(params_fe0_xgb_fr_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# post-training (pickle of models exists)\n",
    "with open('../models/models_fe0_xgb_fr_l.pickle', 'rb') as handle:\n",
    "    models_fe0_xgb_fr_l = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = 1.768496788435238, mae = 1.2642010232676635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>C=C</th>\n",
       "      <th>C#C</th>\n",
       "      <th>Ar</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>...</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>M</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>molecule</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.095</td>\n",
       "      <td>45.2</td>\n",
       "      <td>Trimethylene glycol</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>72.271821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.242</td>\n",
       "      <td>24.1</td>\n",
       "      <td>2,6-Dimethyl-4-heptanone</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>176.435128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.177</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4-Methyl-2-pentanol</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>126.534985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.122</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2-Ethoxyethanol</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>96.801289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.133</td>\n",
       "      <td>21.8</td>\n",
       "      <td>Isopropyl acetate</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>117.151870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C     H  C=C  C#C   Ar  O-alc  O-eth  O-ald  O-ket  O-acid  ...   R4  \\\n",
       "100  3.0   8.0  0.0  0.0  0.0    2.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "160  9.0  18.0  0.0  0.0  0.0    0.0    0.0    0.0    1.0     0.0  ...  0.0   \n",
       "81   6.0  14.0  0.0  0.0  0.0    1.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "103  4.0  10.0  0.0  0.0  0.0    1.0    1.0    0.0    0.0     0.0  ...  0.0   \n",
       "193  5.0  10.0  0.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "\n",
       "      R5   R6   R7   R8        M  measured_st                  molecule  \\\n",
       "100  0.0  0.0  0.0  0.0   76.095         45.2       Trimethylene glycol   \n",
       "160  0.0  0.0  0.0  0.0  142.242         24.1  2,6-Dimethyl-4-heptanone   \n",
       "81   0.0  0.0  0.0  0.0  102.177         22.6       4-Methyl-2-pentanol   \n",
       "103  0.0  0.0  0.0  0.0   90.122         28.6           2-Ethoxyethanol   \n",
       "193  0.0  0.0  0.0  0.0  102.133         21.8         Isopropyl acetate   \n",
       "\n",
       "     density          mv  \n",
       "100   1.0529   72.271821  \n",
       "160   0.8062  176.435128  \n",
       "81    0.8075  126.534985  \n",
       "103   0.9310   96.801289  \n",
       "193   0.8718  117.151870  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_fe0_xgb_fr_ll, mae_fe0_xgb_fr_ll, i_out_fe0_xgb_fr_ll = evaluate_xgb_models(models_fe0_xgb_fr_l,\n",
    "                        X_fe0_test[X_fe0_test.columns.difference(['M', 'mv', 'density'])], \n",
    "                        y_fe0_test, \n",
    "                        weights=None,\n",
    "                        num_outliers=5, \n",
    "                        title='fe0_xgb_fr_ll\\nFragments only, train: liquid, test: liquid',\n",
    "                        x_label='predicted surface tension',\n",
    "                        y_label='measured surface tension',\n",
    "                        with_line=True)\n",
    "print(f\"rmse = {rmse_fe0_xgb_fr_ll}, mae = {mae_fe0_xgb_fr_ll}\")\n",
    "display(df_fe0.loc[i_out_fe0_xgb_fr_ll])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fe0_xgbmv_fr_ll\n",
    "Predicting molar volume from fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 744.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 19.445020288508527                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 514.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 14.778908287045345                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 664.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 19.893134055772425                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 390.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 11.1235074540619                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 131.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 13.851322464429142                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 774.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.750278437568336                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 735.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 12.602702678803164                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 194.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 15.684605809197784                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 872.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 19.68536589071382                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 114.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.07712937483422                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 545.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.379711094720207                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 566.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 6.200515064401284                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 248.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 21.051399115622903                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 311.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 21.33490094241665                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 865.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 11.992646834340333                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 475.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 13.525174367962602                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 968.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 5.092270106751563                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 976.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 12.728201868064094                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 230.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.8841786938126197                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 729.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 22.56267151441385                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 382.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.506330748614073                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 365.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.361010481436532                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 322.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.738546885014637                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 207.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 6.509268930508329                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 379.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.225691059846644                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 446.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.175601152245154                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 626.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.7711870555770695                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 444.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.649192108054078                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 265.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.101681359589363                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 447.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.706903765695244                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 150.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.497391182347546                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 609.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.707955607228235                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 491.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.775202745182958                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 299.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 7.194297021503463                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 206.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.629419488463651                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 423.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 16.39512173443415                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 673.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.159623919208154                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 528.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.284670862785968                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 155.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.100968894734263                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 109.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 9.094221896220978                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 158.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 15.010259875731453                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 246.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 6.309269727042205                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 181.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.2110842947153015                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 121.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.690644866680121                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 102.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 7.636838531814211                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 340.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 6.5975301814890415                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 275.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.495104474108611                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 823.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 14.24316433797901                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 228.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 10.813215659563108                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 561.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.674324733955374                                                                                               \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 166.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 7.375958202414737                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 288.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.701264602561495                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 359.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 20.12966736983097                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 694.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 5.601800462027942                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 404.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.94443556818407                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 934.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 15.100207052946004                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 764.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 6.021500893954749                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 327.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.026019252680093                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 211.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.062318981798882                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 600.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.275433290942286                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 144.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 18.410750903053327                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 477.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.895486628102168                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 417.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 12.729594949856303                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 510.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.668723513816178                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 246.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7528508905431353                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 186.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.8274936738969165                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 228.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.9989256965435525                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 259.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.974297715749847                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 182.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.055175970449253                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 349.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.6574728087306525                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 303.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 6.530679988831814                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 387.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.425586986723885                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 134.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.6720734676408755                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 244.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.807434596083379                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 192.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.7131815881314925                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 277.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.751279534863452                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 323.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.877889006183257                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 100.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 11.44484835730105                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 448.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.201614817223175                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 372.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.15098720652913                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 120.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.051514040873576                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 222.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.896827158579619                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 531.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.725532692097648                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 180.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.561491907728031                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 247.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.578196173065505                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 295.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 12.813249528848536                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 587.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 11.474269828927065                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 654.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.224519252986057                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.407701802964733                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 334.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 19.33984568514572                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 436.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.305359469046985                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 808.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.231503163496774                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 207.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 8.620495481688936                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 164.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 6.014996790060124                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 494.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.908668317291255                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 465.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.752215222814482                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 139.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.159692330827063                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 269.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.458956074575803                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 717.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 6.889284079474804                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 897.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 5.039626076147536                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 357.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 11.257427082944929                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 635.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 19.981763659947376                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 990.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 20.42277484278609                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 310.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.718201954734314                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 104.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 28.01435585683401                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 229.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.9755510480653715                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 396.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.1020039215728525                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 170.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.128573407886799                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 129.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.639888746891287                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 202.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.775108629637373                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 285.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.145218760770054                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 259.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.264789353593676                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 556.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.956525242309005                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 376.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 12.080342616048087                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 578.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 5.9587723549075315                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 428.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.322171395027326                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 509.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.786478883983506                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 465.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.892085316702917                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 428.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.692682749779811                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 609.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 19.72229589559964                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 527.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.637692583736824                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 421.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.557097477062562                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 490.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.515428730619333                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 668.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.667337373997746                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 429.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.526298293520751                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 539.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.220022484135217                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 707.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.659706648831192                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 459.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.37559913306083                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 343.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 13.79046314920238                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 632.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.0059110769801585                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 760.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.922783970160992                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 575.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.609245412671827                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 315.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 7.395717316821739                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 483.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 6.010132524272426                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 391.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.741545651797985                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 512.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.560070466512064                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 355.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 16.944688148489565                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 799.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 13.350042655141861                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 551.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.048220977893039                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.1565612418006825                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 454.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.519939100194616                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 330.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.178537638554946                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 434.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 19.19697805899969                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 374.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.8634750016550794                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 648.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.303737519557504                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 252.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.092393672980925                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 282.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.7357737722621733                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 294.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.982834547514048                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 275.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.868609229383447                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 240.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.7534625969097783                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 597.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.296125526511371                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 347.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.167280831558636                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 315.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.919668880176401                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 368.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.444656715333829                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 214.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.483512295479869                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 406.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.2796035655054556                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 476.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.454659387810873                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 499.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.409093818126166                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 414.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.557147976798166                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 618.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.503091400876881                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 527.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.885768686117207                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 395.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.1375118443579595                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 335.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.452997050942023                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 443.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.037333681645141                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 564.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.6140511103574795                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.867652628086344                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 305.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.4083969016649265                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 474.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.691191143009934                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 435.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.147456339196788                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 694.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.766539721548322                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 503.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 6.3646070708987255                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 540.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.003246028842324                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 362.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.866395368340267                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 410.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.489702663335862                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 273.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.5419390527147225                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 850.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.008163823034558                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 454.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.40115982612384                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 592.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.842215232830357                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 735.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.18675865650307                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 516.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 19.526371526593337                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.3115544292777095                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 325.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.545076675034122                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 291.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.143471367761791                                                                                               \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 388.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.877598866992065                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 351.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.303766840704857                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 188.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.344438967338142                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 687.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.206629716187683                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 483.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 11.313242950969725                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 948.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 7.76887310078675                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 226.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.564232561950315                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 553.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 19.552870818655947                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 262.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.8513419341768635                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 462.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.810184939453769                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 144.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.6460658439200335                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 579.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.1846781667917865                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 374.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 5.408243279790966                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 644.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.6667639060879385                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 305.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.3687962053785405                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 521.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.9675105925818297                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 400.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 5.387170595079173                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 436.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.604678092108973                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 162.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.35992391206755                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 206.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.567365666344791                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 492.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.319112824405684                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 340.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.413725426890076                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 620.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 15.298275244816011                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 335.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 5.254378414210918                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 538.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.955204110299616                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 452.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 19.70996506090952                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 427.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.856823596995041                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 357.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.240786362939358                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 675.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.130474094784293                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 566.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.739760226708773                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 416.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 18.115232163834673                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 467.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.732954782093018                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 240.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.111967218426104                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 318.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.734411176527563                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 500.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.713145240976612                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.287958780162163                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 605.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.0203084157024565                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 286.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.036346040405881                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 344.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.304882014234018                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 372.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.9614250873063215                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 479.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.503436659292556                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 398.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.459816530224013                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 442.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 13.376204151622018                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 513.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.022207577943259                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 262.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.7557777738398106                                                                                              \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 544.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.093359860577171                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 309.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.878209863671405                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 412.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.515922234196493                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 584.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.724456346524722                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 330.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.177809838723703                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 751.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.567022473121117                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 792.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.163256062422216                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 355.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.879347736320721                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 719.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.215888828275946                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 122.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 14.75695415136888                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 466.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.83101881515693                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 180.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.562114184259233                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 527.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.580218767595901                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 443.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.074286630437678                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 293.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 6.835534460709483                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 219.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 10.76695616299468                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 486.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.560848877980089                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 660.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 21.3780397538381                                                                                                \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 377.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.627712979675964                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 244.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.617469846074368                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 567.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.717942035965118                                                                                               \n",
      "\n",
      "\n",
      "iteration: 1. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 403.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.295761893092728                                                                                               \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [02:27<00:00,  1.69trial/s, best loss: 3.2796035655054556]\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 894.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.11956246180322                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 927.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.164356051518323                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 218.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.424427700041999                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 610.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.948339679165741                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 315.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.751280775155285                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 930.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.815613525367225                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 119.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.025187175647501                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 543.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.165489762056316                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 285.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.528479666543904                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 734.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.057996346291688                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 196.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.220020885369835                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 470.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.545104694409903                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 738.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.2452709096918317                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 938.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.064280009234995                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 748.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.2644841107039437                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 299.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 5.357259222161697                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 186.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.076042534556033                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 193.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.235262795038251                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 113.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.166455828084008                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 817.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.138819012039949                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 704.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.013863538218856                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 802.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.07910060806712                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 644.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.6867200600757513                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 453.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.452952418812756                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 838.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.9181480849103805                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 988.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.217598467010025                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 979.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.308257662913943                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 649.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.9750400221591695                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 833.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.021417748905292                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 992.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.17066091015551                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 993.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.1693109577561014                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 995.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.5553433151186646                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 883.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.2100920571878895                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 886.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.31862946688887                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.42643829085873                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 578.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.5494304625620736                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 933.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.9369289864768993                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 537.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.839125077020787                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 363.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.9793895914684763                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 958.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 6.046995966119502                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 777.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.63170733689954                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 878.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.351237840179439                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 663.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.952950254843838                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 692.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.5166840755425195                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 509.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.778244786056416                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 610.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.0352795211215575                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 910.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.7429462677293257                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 768.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.871900569199064                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 364.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.138555427232041                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 240.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.816344117157876                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 845.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.685576782487401                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 710.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7726677984614465                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.668541692861625                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 959.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.910190237763209                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 148.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.594366934486312                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 860.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.558549177492101                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 783.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.213675348290038                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 597.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.695512175931579                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 809.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.50158045817164                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 738.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 6.529083274492503                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 914.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.282134751055317                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 963.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.6068338885885898                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 424.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.1974817972807035                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 348.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.021105364451406                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 487.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.382204959667882                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 982.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.215785297235179                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 906.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.6933475346099773                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 937.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.6339662148753114                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.443625094126074                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 872.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.4881691306897626                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 824.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.591233815688746                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 948.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.5575995554816444                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 977.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.583397002365922                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 791.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.5766925035598054                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 674.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.125522198560033                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 923.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.809011496713972                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 851.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.0780033366047315                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 636.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.1932404588403696                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 556.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.2486225506976774                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 764.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.8486336774989667                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 240.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.9837624413628268                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 418.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.5071708945022753                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 623.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.202291275472753                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 517.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.051071522609987                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 284.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.9899237754604933                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 448.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.3107244014610977                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 725.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.788745166563573                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 578.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.5271509389016495                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 695.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.142539410370305                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 152.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.772590724002861                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 895.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.892546450951827                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 383.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.52756024595334                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 644.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.301516705884981                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 292.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.777510754207688                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 331.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.630260455305447                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 669.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.8249435444144124                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 760.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.103453753960376                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 800.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.78340208652598                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 719.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.203108193614579                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 399.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.6057016881690185                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 863.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.266987657794752                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 834.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.577151778046638                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 103.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.680971368930604                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 482.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.122416729352234                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 745.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.937065859126724                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 894.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.392804872640467                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 630.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.987202714833126                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 969.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.867593204578393                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 560.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.7022886476956085                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 521.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.132284546608159                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 531.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.234707039535291                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 593.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.306375808352692                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 457.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 2.989046880661555                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 260.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.267365950959552                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 468.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.0112724186200595                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 324.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.840072163940111                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 498.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.4334413040274                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 200.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.432303796316491                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 429.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.829759790684535                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 461.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.6231757457709013                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 377.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.572698729120892                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 345.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.496578966413389                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 532.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.59580278903922                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 399.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.422121180151163                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 302.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.127307799859489                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 447.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 6.465294147415299                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 610.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 5.2407074471467725                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 571.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.8051119199739865                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 135.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 6.890355710958269                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 521.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.474987577296211                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 273.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.373625259910675                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 175.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.990981887230402                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 502.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.486221633421836                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 677.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.31138659232261                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 657.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.923752642223812                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 546.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.381293045997952                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 404.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.670925587519914                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 484.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.5927405588942154                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 234.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.8513054865613405                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 594.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.088652150185282                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 436.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.492154218828304                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 347.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.8110253575615145                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 382.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7469259238215886                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 314.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.720687427960542                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 579.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.416522991206683                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 685.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.395153150280923                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 473.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.8389951669562294                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 938.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.2031014021631163                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.119020387482805                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 811.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.2202165200021162                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 511.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.7799836923084142                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 713.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.081050480531477                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 707.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.4321693184859003                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 626.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.365128291792522                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 611.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.913352135660161                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 562.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.3776355540337017                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 549.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.7512136377121035                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 782.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.323871074323134                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 650.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.5150324937952595                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 451.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.3340977721556175                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 411.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.70251779897684                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 748.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.940350760935692                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 586.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.401213764861976                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 490.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.2674136996038827                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 530.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.503959501631651                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 355.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.058993446979685                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 435.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.3668738073717677                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 366.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.697678549781573                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 467.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7136535379790527                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 724.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.9292881074375137                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 391.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.430180590169671                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 256.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.7159795687065262                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 845.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.670254416795071                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 212.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.488043519126193                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 508.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.57308019433385                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 697.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.4112836442395                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 607.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.1599463393159875                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 644.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.436063186701176                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.093757048057175                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 372.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.5401227310671453                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 335.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.686456944213265                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 315.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.8968391068756683                                                                                              \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 421.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.5758823798985997                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 448.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.5704020948703343                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 545.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.2422143171510975                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 299.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.145236238797208                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 664.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.8890679701950095                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 568.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.318560598108342                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 617.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.747028892509338                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 174.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.486974749095643                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 283.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.111072268734161                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 473.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.077641911078435                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 260.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.8218303529525484                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 523.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.3466159398034807                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 498.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.9529416084703763                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.474535049758154                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 736.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.448648705160297                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 763.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.427494425584092                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 432.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.7112792134323627                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 634.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.3000644978256775                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 226.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.221729823311024                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 588.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.6267455804562814                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 488.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.523627021537748                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 538.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.0183008730617886                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 794.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.919984708699417                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 388.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.076451614198232                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 683.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.3324510900711584                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 459.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.796265300022586                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 712.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.5543091286998365                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 541.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.632417723925688                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 343.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.845488128925329                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 600.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.3169717249998527                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 574.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.418896765393558                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 666.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.65794535706136                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 555.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.984222075768527                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 818.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.307046312559755                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 506.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.320782532964549                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 360.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.9437921820486452                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 324.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.263025016040104                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 410.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.426223419523035                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 440.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.256541092318911                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 878.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.00086092488759                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 650.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.479795366295804                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 476.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.8058799508506564                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 306.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.878449089610747                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 624.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.105791323750761                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 371.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.132512983683493                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 118.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.7934701293782975                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 531.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.126799042147347                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 701.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.442687759936863                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 420.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.668579727021421                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 777.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.8139980142632934                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 560.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.439038296705177                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 749.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.680977748923529                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 274.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.40698208780365                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 457.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.375310865074232                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 398.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.136328774802718                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 204.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.559507706496901                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 488.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.280444207127736                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 248.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.2207253685679555                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 518.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.161132003608458                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 727.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.844665697011773                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 583.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.755302145467423                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 679.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.9137013302677097                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 828.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.030334904748757                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 913.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.1283946405848755                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 856.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.2008308967598684                                                                                              \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 836.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.668403051086018                                                                                               \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 947.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.27245362819314                                                                                                \n",
      "\n",
      "\n",
      "iteration: 2. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 825.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.43543498293882                                                                                                \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [02:51<00:00,  1.46trial/s, best loss: 2.989046880661555]\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 396.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 26.213413997129333                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 129.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 37.532703055375144                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 506.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 26.657562947697787                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 751.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 19.576967265634686                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 675.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 19.802413384913308                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 391.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 25.034461196001345                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 812.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 24.982150318495332                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 169.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 19.23257299183768                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 680.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 25.329374627039908                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 453.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 26.56742912568182                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 442.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 18.76289129653097                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 960.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 22.126912630727013                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 318.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 19.495083986081035                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 203.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 17.465554792332803                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 752.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 21.76455320736659                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 152.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 43.94996028999737                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 758.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 27.593320271465224                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 431.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 27.001985792527726                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 971.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 26.52333471385021                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 136.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 20.608312878498793                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 258.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 7.066963756413062                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 260.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 7.067709665339569                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 247.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 7.103035322048496                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 291.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 6.91442416879498                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 317.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 8.049182093634265                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 553.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.094892880105486                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 331.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.657572889186573                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 537.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 17.70680513835531                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 101.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 8.428185977123464                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 246.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 16.730555744850253                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 633.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.776530831906204                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 607.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 17.739031997240712                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 902.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.661774158139301                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 615.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 17.346645550048212                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 868.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 8.658108912901168                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 498.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 17.34455415682782                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 377.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 19.066105616608848                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 698.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 9.875306563338844                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 587.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 26.270412872483796                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 643.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 18.899529922600646                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 487.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 26.452816535145978                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 811.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 17.167743664591583                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 713.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 11.50948349917531                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 26.402639858103555                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 551.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 16.547283018805427                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 808.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 19.23812529843609                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 650.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 25.596973491466944                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 462.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 25.844380284064965                                                                                              \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 340.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 16.899926792742235                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 208.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 20.27317263737926                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 414.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 11.30703283423884                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 852.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 26.569749936896063                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 184.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 22.399767280067508                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 727.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 12.49669292997457                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 296.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.539700536546306                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 928.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 27.3140047613343                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 766.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 27.139180587444763                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 677.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.341876560968396                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 107.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 18.7602711831765                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 527.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 14.216807030937568                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 361.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 16.59093349366034                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 582.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 19.374708485511878                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 283.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 12.240188075525895                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 454.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 18.12363724840951                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 210.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 27.168388298318128                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 144.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 7.426225627581197                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 230.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 6.926556922765872                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 169.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.5863907351665345                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 7.090422241924297                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 233.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.79678095519183                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 412.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.94781348183069                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 274.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.77883285671565                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 286.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 16.937564732242393                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 647.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.856570027799253                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 771.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.666902289008891                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 642.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 17.342556480306623                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 738.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 8.413872024653257                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 520.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.43357319011418                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 572.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 8.615659611490443                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 611.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 19.243099309616056                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 483.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 7.5832510813565195                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 838.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 17.404625096517258                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 786.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 13.158038178974955                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 697.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 17.798790056899712                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 656.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 20.70462833225998                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 555.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.0562038104714135                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 900.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.472355285035072                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 628.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 19.76482590926752                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 434.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 26.20922419202723                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 477.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.525241161934634                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 515.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 27.390854047962847                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 600.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 9.282196042685214                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 702.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 20.113391964306395                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 674.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 10.872092913477768                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 567.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.534982788420834                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 787.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 11.17541155258915                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 7.792807809980493                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 873.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 25.455744478147917                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 727.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.536678396833338                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 121.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 25.80236238756354                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 354.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 17.35750382540631                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 534.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 20.101497320304244                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 315.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 7.987721583219555                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 624.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.5806994740100775                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 501.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 9.359188863213399                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 17.957894362433358                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 399.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 19.01908306266684                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 732.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.828349343519176                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 895.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 17.641698463273517                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 947.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 27.590122660281672                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 594.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 10.523410093823427                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 796.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 26.198289425422796                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.409419864426448                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 760.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 18.734232931110117                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 744.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 27.381286355089255                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 463.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.905037400569896                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 668.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 17.961352527258434                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 822.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 14.853333739006427                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 851.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 19.656279289170268                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 975.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 18.57259768599746                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 723.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 8.791640525059387                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 262.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 18.714658126195427                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 690.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 17.976679385617693                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 919.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 10.457108687697131                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 870.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.531609170176133                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 370.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 17.435212238841856                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 185.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 29.10798837456276                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 551.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 26.246868782050388                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 392.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.56486544177606                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 342.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.4810924710939615                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 392.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 19.792131670822858                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 325.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.0178067670328925                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 230.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 24.34909850945776                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 269.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 16.20697789921336                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 160.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 32.67285164773186                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 310.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 25.805338674535182                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 442.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.416992190876754                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 192.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 22.635612721577598                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 356.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 9.53870858016414                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 300.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 20.12911639026849                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 377.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.539375871655876                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 379.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 12.031136505929                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 406.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 17.27503795244601                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 475.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 20.201916357163075                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 441.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 13.856625671041702                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 279.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.552645624254822                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 250.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.653767854816901                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 127.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 11.589218861127051                                                                                              \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 217.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.940331610133524                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 239.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.855762037494692                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 343.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.516365751416604                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 339.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.508391797160815                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 281.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 10.175572853544969                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 426.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.962361319606719                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 495.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.799423242689734                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 353.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 8.68776118718831                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 296.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.5204421395520145                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 143.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.226919979296365                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 207.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 8.189525222268724                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 174.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 16.07900224614264                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 293.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.51339603611865                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 106.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.058207768518535                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 327.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 14.123403166416958                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 222.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.6821315662544105                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 259.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 7.076847830902506                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 307.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 17.138841592553447                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 373.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.222777108974261                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 453.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.589572908069112                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 411.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 13.002299635335852                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 243.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 17.557760097479456                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 281.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 12.455268134409394                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 199.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 24.899327049381842                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 159.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 13.26128653790631                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 334.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.324161403959625                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 510.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.26229499400703                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 364.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 18.672263685666767                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 320.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.785411783861386                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 115.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 19.800493315703818                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 179.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 23.234995045610123                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 265.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 7.802308551778662                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 462.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.57472568524279                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 426.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 8.123808902402216                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 534.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 17.85394117804516                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 385.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 12.232243567217235                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 479.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 7.348668196760914                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 294.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 25.853625573663958                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 148.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 19.712405642810367                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 398.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 19.451488826087452                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 348.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.254059332922869                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 219.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 21.03256654808884                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 251.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 16.898112820761366                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 306.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 14.429326188608336                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 128.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 18.6338661243499                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 580.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 6.982150040501101                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 6.0, 'n_estimators': 205.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 29.194547322285203                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 449.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 26.018570014427585                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 101.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 20.1194598995221                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 280.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 16.216165132834195                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 418.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 25.817219114299206                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 366.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.486611692344865                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 335.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 19.47781870386755                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 237.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 20.07411954031728                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 499.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.192517431894961                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 190.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 10.252975901094231                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 167.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.00775241335374                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 390.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 8.555000601437762                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 313.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 7.699021272627838                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 264.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 20.790636788912355                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 564.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.004526432867614                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 518.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.215524177515555                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 540.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 16.727383523698037                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 351.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 9.618120204233383                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 439.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 12.57115219043183                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 467.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.61567236858239                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 372.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 11.944014642218159                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.394271909424001                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 293.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 17.629647344414014                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 137.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 34.930654575606006                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 227.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.549477987852512                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 483.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 25.849946548112985                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 334.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.3248255273016                                                                                                \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 196.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 25.186982409903717                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 247.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 9.450194887552668                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 275.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 20.401126518654113                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 317.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 16.91141098210716                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 157.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 9.715448942389715                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 391.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 26.112863180456614                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 432.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 19.406244084284346                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 612.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.6431403100510344                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 179.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 16.57682213725141                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 211.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 15.254963030657425                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 350.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 14.370057798556374                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 292.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 16.38994200697013                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.9490156123612765                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 257.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 25.36763044596348                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 374.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.552347019369331                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 491.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 17.261515457673525                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 593.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 15.845071190628893                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 458.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 18.767361179669177                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 382.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 20.548788390552332                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 548.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 7.094452770512368                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 521.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 16.64445759929757                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 426.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 9.029577264744413                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 502.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.314081449690873                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 321.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 12.394661386218198                                                                                              \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 362.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 16.08045922775541                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 415.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 6.914884571851174                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 307.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 25.00039494269692                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 574.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 10.54991992154904                                                                                               \n",
      "\n",
      "\n",
      "iteration: 3. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 449.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 16.891533729907476                                                                                              \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [03:18<00:00,  1.26trial/s, best loss: 6.516365751416604]\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 277.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.459652564808841                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 251.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 12.601001145035898                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 139.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.002313634570154                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 144.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.878791446614972                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 4.0, 'n_estimators': 430.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.627989841600313                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 224.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.674072533791263                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 335.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 5.480375948953711                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 323.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.063682074025424                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 786.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.119689001403687                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 187.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.784404162690011                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 496.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.507523544638215                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 894.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.337857643835793                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 535.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.267810695769991                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 294.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.694587573590269                                                                                               \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 341.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.975207666773589                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 556.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.814823988614477                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 6.0, 'n_estimators': 198.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 5.037234005192249                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 303.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.639776405111863                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 906.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.726436741879801                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 633.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.4475051359145734                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 670.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.404005882497054                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 674.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.384296831220832                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 676.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.9454236321928176                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 671.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.9594170840861382                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 780.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.37949715926362                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 778.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.769675105007558                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 982.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.0651283178545325                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 774.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.344440470196234                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 598.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.09581995614486                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 851.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.058281047207317                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 993.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.3907317119056355                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 464.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.320171384123019                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 594.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.752189374403142                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 393.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.381552152574862                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 711.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.108567676868538                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 832.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.497505526426659                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 934.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.244389089072627                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 732.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.1615537746634885                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 614.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.134952096832413                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 834.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.4598148180031965                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 415.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.911993352133168                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 510.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.646197582465022                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 730.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.370043337081345                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 633.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.3097552326913915                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 561.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.590229330425461                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 946.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.534679811812484                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 876.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.149634919604603                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 468.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.640005380751886                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 126.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 6.215460247330198                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 5.0, 'n_estimators': 254.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.652076290034883                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 380.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.267971706147183                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 803.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 6.680042250023451                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 741.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 6.956497292881272                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 526.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.396157311542195                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 630.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.334424054586265                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 569.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.478726361507161                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 466.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.340901092176025                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 703.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.018162430662822                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 767.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.9409180114481237                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 649.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.722154111332071                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 167.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.934869240027203                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 966.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.8840084736468743                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 899.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.8891185132454487                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 345.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.59112194630835                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 807.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.543297971081357                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 942.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.884451614923794                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 962.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.5794143737634316                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 856.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.62400429951051                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.569908005941956                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 914.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.745448135612533                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 968.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.084750396669755                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 227.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.470386275077066                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 886.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.624624060045467                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 862.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.6325516384932444                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 921.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.450281589356289                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 101.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 24.03757444504394                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 825.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.50501388330342                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 989.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.8372253814264825                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.546642633999714                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 691.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.6697749954652665                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 757.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.610461471404824                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 798.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.990899112547716                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 432.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.168154205148594                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 288.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.865158611809247                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 572.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.089866309697921                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 369.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.2392001284257566                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 491.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.334249306402008                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 540.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.418516946258927                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 953.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.436532041651137                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 824.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.911941791503478                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 876.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.1159262131748715                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 657.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.708206174776143                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 751.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.5508451544519035                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 928.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.268770850826796                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 588.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.707722897957069                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 313.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.554249430307135                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 717.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.607377079115184                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 847.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.5214679327295535                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 431.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.91040762097126                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 616.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.506400024780271                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 969.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 5.374604981333386                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 689.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 6.265949294681171                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 256.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.33481400383949                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 785.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.591608257590928                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 523.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.522195697483602                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 404.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.498904259052057                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 201.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.546228736384849                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 907.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.3764901608503743                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 903.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.5880177967743734                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 726.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.506748886694227                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 640.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.7426974174006795                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 663.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.378841460214747                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 503.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.063090259443949                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 611.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.481556880952802                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 446.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.6459963086911533                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 483.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.840827824012175                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 577.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.979705684934573                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 670.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.4590063197482985                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 546.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.255895237215387                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 695.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.707263348546156                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 656.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.9212341453589215                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 740.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.646272203000551                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 352.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.197664951817341                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 803.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.890558576521278                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 764.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.8678490318449796                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 515.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 5.043991755130118                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 625.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.940499648628859                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 559.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.529104896022292                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 816.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.92723566168114                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 458.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.394992359729407                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 606.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.8271457551741053                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 713.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.259411276456718                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 485.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.1006581597276766                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 839.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.985033258371535                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 860.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 5.72520443621879                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 880.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.892964082710825                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 385.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.812366253903058                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 584.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.6051353346518336                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 786.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.412468114384212                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 678.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 6.36182514136962                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 408.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.300328718472885                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 534.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.471268323342927                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 640.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.657614731777398                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 322.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.129316143877739                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 278.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.526997629431937                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 656.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.2581245334166673                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 593.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.3454787069825374                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 749.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.6878576922807844                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 598.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.057505923453436                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 659.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.5570686369147064                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 555.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.733904242494279                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 708.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.8810840803237925                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 444.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.460634790551693                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 771.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.359473169447059                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 733.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.293366359098456                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 683.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.210916835330905                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 734.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.861774656147167                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 679.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.233090040402391                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 783.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.161960491786544                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 715.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.249037572708068                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 684.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.625181747824873                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 752.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.891402679288573                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 620.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 6.428498929957905                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 696.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.175821959215684                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 573.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.269307425040668                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 639.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.1106531382629576                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 634.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.95335612185122                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 700.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.017586822868589                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 702.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.0151224385072357                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 700.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.244655102371454                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 817.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.11663989093116                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 793.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.0875719266334647                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 936.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.379661454127762                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 842.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.7999574186841127                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 794.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.287376418731419                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 755.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.129273689087414                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 882.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.12274090545554                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 870.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.380875411515459                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 776.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.1051914981515143                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 810.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.8072692586374965                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 850.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.8209120977968283                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 894.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.160669765947683                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 833.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.068543957539666                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 974.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 5.26125190921346                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 915.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 2.937410335269758                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 912.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.7457639450918605                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 940.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 3.819059017924698                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 991.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.126602624070487                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 830.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 5.08948469149076                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 960.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.9762459552828116                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 10, 'min_child_weight': 4.0, 'n_estimators': 928.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.419118381685087                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 859.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.9572949369383172                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 869.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.640856365126618                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.8178027668786285                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 984.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.905389780413029                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 947.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.9736761141851                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 891.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 2.8569758381813672                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 919.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.9089687743601305                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 902.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.432434370815389                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.9789744712471755                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 959.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.7007682322863142                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 974.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.490542413599357                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 887.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.773031016086467                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 997.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 6.61763881104415                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 922.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.406923945087611                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 860.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.874252410191522                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 128.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.069523301523912                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 983.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.492472961405851                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 948.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.5704063776920107                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 895.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.1326604877229425                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 936.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.132230420128472                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 845.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.005315852126868                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 959.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.568035323122097                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 916.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 5.595914274436777                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 815.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.1221770069470685                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 865.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.882438725315224                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 882.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.229943919818925                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 975.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.699054595735372                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 904.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.665467529278314                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 165.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.253213806398663                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 767.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.535117966688636                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 798.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.150401942032492                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 995.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.993627000694269                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 828.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.5289493280644555                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.770776812258331                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 939.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.4008339636381097                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 890.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.919209878531738                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 848.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.618289106527777                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 954.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.6657665232663303                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 868.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.273749766813787                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 926.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 6.239914199816641                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 725.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.625727067526655                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 973.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.37489857711114                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 906.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.346587571155253                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 812.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.621352284291713                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 777.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.155316765994421                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 836.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.364337400039078                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 999.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 5.54232751454394                                                                                                \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 742.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 5.970661567352428                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 861.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 5.617175760832876                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 953.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.994657070178225                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 233.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.992019995946693                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 361.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.175433929174686                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 1000.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.543763982093629                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 928.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.315640446078678                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 804.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.292336623067691                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 759.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.654461753352694                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 966.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.420938760097077                                                                                               \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 883.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.7682171552019295                                                                                              \n",
      "\n",
      "\n",
      "iteration: 4. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 908.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.229917167577412                                                                                               \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [03:38<00:00,  1.14trial/s, best loss: 2.8178027668786285]\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 1, 'min_child_weight': 6.0, 'n_estimators': 980.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 13.90890050281099                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 843.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.8342675992456408                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 479.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 11.39134963720523                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 946.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.143927411775288                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 962.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 8.080848366061412                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 975.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 9.80258345840451                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 141.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 9.930473469669618                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 12.443371097908473                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 897.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 9.403747404697897                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 609.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.721034890546214                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 400.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.192693046707675                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 281.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.037184105187592                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 206.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 7.151646946365242                                                                                               \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 985.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 12.217234294809396                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 787.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 6.173092591244113                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 638.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 6.561363401051745                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 5.0, 'n_estimators': 405.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 12.345009680912604                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 538.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.914474938154064                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 532.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.684937160707004                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 831.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.195123070922972                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 253.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.8440826340918774                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 711.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.156452241461121                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 286.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.8714453901383545                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 714.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.5595103238069976                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 722.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.364462312524528                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 853.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.867442492016902                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 740.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 11.327381817985266                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 647.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.553460935605829                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 643.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.108660036806095                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 442.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 12.144920392411459                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 594.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 12.57432332083308                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 675.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.654370419483456                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 777.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 11.444397147090386                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 476.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.2278209175008925                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 345.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.345883187239099                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 902.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.4548853046656625                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 4.0, 'n_estimators': 573.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 10.124752763351928                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 6.0, 'n_estimators': 492.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 13.412528278976914                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 674.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.923333748360288                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 804.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 10.836737160380096                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 873.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.50121993696001                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 761.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.728636147895272                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 931.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 11.100497410217798                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 690.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.415632227740689                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 625.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 7.9440906194463246                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 681.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 12.25413714361003                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 370.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.474559211661441                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 562.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 6.007855097599879                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 6.0, 'n_estimators': 518.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 13.11172354883371                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 816.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.6124155911944245                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 946.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.929545811809608                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 457.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 8.75668364059656                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 105.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 12.410503985763485                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 414.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 4.695978719426414                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 170.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 11.317989931000183                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 501.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.7889438361655                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 588.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 12.999671489150964                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 657.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.738662591304748                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 743.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 8.482481197886678                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 614.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 3.7955647960271093                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 338.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 7.534790044677698                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 895.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.239951431039423                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 847.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.298511529006462                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 985.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.553829958213523                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 696.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 10.103600472831204                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 787.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.262233884675126                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 731.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.644086635784037                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 764.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.879354740286765                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 532.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.958439846753565                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 713.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.57654312940211                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 639.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.087018537877566                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 562.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.008838089127377                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 866.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.5160604839315694                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 916.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.64136514007709                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 876.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.789222677225959                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 963.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.865638936083343                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 807.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.307275378370781                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 868.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.890669362299897                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 998.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 9.452318752524967                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 602.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 5.944220531735676                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 6.0, 'n_estimators': 834.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 13.354143630771578                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 664.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.2901845350006464                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.1, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 699.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7552331063712954                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.08, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 4, 'min_child_weight': 3.0, 'n_estimators': 756.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 9.174267330206789                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 822.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.7384125664893273                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 435.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.3591300192030458                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 287.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.105204559705919                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 260.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.392833404142528                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 457.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.882935697922107                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 428.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 12.25319786343806                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 376.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.2260377416420907                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 384.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.277017481302523                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 184.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 6.70398730692128                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 351.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.668944770704811                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 320.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.8500877277127                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 3, 'min_child_weight': 4.0, 'n_estimators': 240.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 11.684060085253357                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 140.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 22.512961388586376                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 313.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 6.850749212199247                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 385.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.8645209360618034                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 490.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.724399877113864                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 513.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.7090599311761507                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 216.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 8.757599510201471                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 471.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 7.612049698999158                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 433.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.512247874174143                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 546.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.50424549184609                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 409.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.778537362909375                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 9, 'min_child_weight': 4.0, 'n_estimators': 585.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 10.488344076960196                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 356.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 3.8691713158621974                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 12, 'min_child_weight': 3.0, 'n_estimators': 297.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 8.495644143913202                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 1.0, 'max_depth': 10, 'min_child_weight': 2.0, 'n_estimators': 110.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 7.6435221897571965                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 623.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.319601454004224                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 458.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.450725054619383                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 624.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.334565008296476                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 629.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.952638074392279                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 561.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 12.412228074960543                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 518.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 8.027349554563154                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 574.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.432951180153965                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 2, 'min_child_weight': 5.0, 'n_estimators': 532.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 12.87629723161689                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 605.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.992867201261819                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 646.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.595320106348921                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 2, 'min_child_weight': 1.0, 'n_estimators': 616.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.274925483375618                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 777.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.280457666141593                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 396.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.66780116334444                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 260.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 16.26237293091149                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 663.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.209597533132207                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 792.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.6025635967603113                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 734.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 4.694660103467977                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 715.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 12.384991197619113                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 662.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.113367250816141                                                                                               \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 499.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 11.928663624761711                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 364.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 5.070318790464554                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 332.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 6.542400997198976                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 683.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 12.889974562706296                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 480.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.872702434639564                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 584.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.8803341274475165                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 202.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.047549252196664                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 2.0, 'n_estimators': 543.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 7.203411123275922                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 757.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.98170125986105                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 146.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.788218839637505                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 9, 'min_child_weight': 3.0, 'n_estimators': 421.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 7.083827054141144                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 447.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.1499843356386226                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 304.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.5919327040795                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.5, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 228.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 7.798133005482582                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.55, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 380.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 10.971412668580141                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 327.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 6.659399839218868                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 465.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.222310641930577                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 274.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.2537458179271095                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 450.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.702794045154419                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 478.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.213813590588818                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 510.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.5549198445218146                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 407.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.504628452372485                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 483.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.4787438341394266                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 467.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.0155537715301834                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 441.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.5144623130055233                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 594.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.5383660162132355                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 526.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.202725057906499                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 571.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.980547817420152                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 548.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.137067319573743                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 519.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.620920997016827                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 651.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.9787449979295157                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 494.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.791754483487777                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 670.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.4907594863357456                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 529.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.42079181582974                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 698.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.8219951680036615                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 5.0, 'n_estimators': 559.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 13.696614888705485                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 394.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.758679800561235                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 636.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 6.0217824879225095                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 418.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.361277542237738                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 354.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 13.741715283320433                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 602.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.5421265481258715                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 498.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.4486104470629844                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 437.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.2142733349812453                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 578.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.162490138152732                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 739.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.435879570673083                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 699.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.349693469978215                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 719.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 6.735263395783125                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 582.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 5.033332466061929                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 675.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.7989830200421104                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 843.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.860254577041173                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 612.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.1185079053608318                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 541.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.009367794195991                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 621.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 8.967056813830323                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 522.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 1.0}\n",
      "\tScore 4.357479251515078                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 561.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.582470912765529                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 4.0, 'n_estimators': 610.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 10.341390676903266                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 650.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.7800705648415454                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 452.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7648956071960518                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 506.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.689812214304716                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 791.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 4.560150964480127                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 590.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 8.19589613011829                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 766.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.563691425899264                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 369.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 3.9616532936971196                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 3, 'min_child_weight': 1.0, 'n_estimators': 405.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.5086624539451035                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 3.0, 'n_estimators': 338.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 6.68549804772192                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 541.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.386028430714567                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 633.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.231896553925403                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 4.0, 'n_estimators': 475.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 10.433189187907182                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 422.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.848484274652772                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 278.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.55473205479095                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 689.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 6.356202554841066                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 572.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.086762100835833                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 808.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 3.918317809299851                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.5, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 749.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 6.0998124558955                                                                                                 \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 308.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 12.426979894083386                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 603.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.656142110948212                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 722.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.6798361828797694                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 558.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.052195725221187                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 3.0, 'n_estimators': 529.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 7.163504800220448                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 445.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.205800338205117                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 1, 'min_child_weight': 3.0, 'n_estimators': 490.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 8.149502445567116                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 7, 'min_child_weight': 4.0, 'n_estimators': 943.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 10.637833379528695                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 380.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 3.7716047581135594                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 507.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.6301588114756664                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 1.0, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 887.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 4.64307806081061                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 461.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 4.043069437766527                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 913.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.8956539440459994                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 2.0, 'n_estimators': 639.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.050036912412779                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 661.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 12.699748497463787                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 595.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 3.7142707742964607                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 430.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 5.117664754962226                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 702.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9}\n",
      "\tScore 5.2065863362340705                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 6, 'min_child_weight': 3.0, 'n_estimators': 572.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 7.879212687670762                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 1.0, 'n_estimators': 348.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.95777487708538                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 253.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 7.449080341514531                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 548.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.9170185664912665                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 617.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 4.061815581155216                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 771.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 7.775939603457023                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 686.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.677876221218236                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 319.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 4.66448138926049                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 490.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8500000000000001}\n",
      "\tScore 4.135510522091623                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 400.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 12.799705418851008                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 2.0, 'n_estimators': 194.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 4.156756025143367                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 11, 'min_child_weight': 2.0, 'n_estimators': 524.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 3.552179639978652                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 829.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 11.35835094252978                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 471.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.154025733648599                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 4, 'min_child_weight': 1.0, 'n_estimators': 733.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.4501948444710653                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 7, 'min_child_weight': 3.0, 'n_estimators': 226.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 11.898565333474956                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.9, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 296.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 3.73456580373719                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.9500000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 2, 'min_child_weight': 2.0, 'n_estimators': 653.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 5.53620742279837                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 8, 'min_child_weight': 2.0, 'n_estimators': 588.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.6596627829376684                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 10, 'min_child_weight': 1.0, 'n_estimators': 156.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 18.658650954585948                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.6000000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 363.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.75}\n",
      "\tScore 3.9767410808826673                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 672.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.5}\n",
      "\tScore 6.846162504021873                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.7000000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 550.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.8}\n",
      "\tScore 4.122482537040391                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.75, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 445.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore 4.018385249857581                                                                                               \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.65, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 12, 'min_child_weight': 1.0, 'n_estimators': 389.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.6000000000000001}\n",
      "\tScore 3.6432920094611587                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.8, 'max_depth': 3, 'min_child_weight': 2.0, 'n_estimators': 419.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.65}\n",
      "\tScore 3.7502814897721377                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.7000000000000001, 'eta': 0.04, 'eval_metric': 'rmse', 'gamma': 0.75, 'max_depth': 6, 'min_child_weight': 5.0, 'n_estimators': 624.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.7000000000000001}\n",
      "\tScore 12.244367342968177                                                                                              \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.8500000000000001, 'eta': 0.02, 'eval_metric': 'rmse', 'gamma': 0.8500000000000001, 'max_depth': 11, 'min_child_weight': 1.0, 'n_estimators': 117.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.9500000000000001}\n",
      "\tScore 26.3068379325534                                                                                                \n",
      "\n",
      "\n",
      "iteration: 5. Training with params:                                                                                    \n",
      "{'colsample_bytree': 0.55, 'eta': 0.06, 'eval_metric': 'rmse', 'gamma': 0.65, 'max_depth': 8, 'min_child_weight': 4.0, 'n_estimators': 499.0, 'nthread': 6, 'objective': 'reg:squarederror', 'seed': 42, 'silent': 1, 'subsample': 0.55}\n",
      "\tScore 10.912571670282794                                                                                              \n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [03:36<00:00,  1.16trial/s, best loss: 3.1185079053608318]\n"
     ]
    }
   ],
   "source": [
    "models_fe0_xgbmv_fr_l, params_fe0_xgbmv_fr_l = run_xgb(X_fe0_train[X_fe0_train.columns.difference(['density', 'mv', 'M'])],\n",
    "                                                X_fe0_train['mv'],\n",
    "                                                space,\n",
    "                                                k=5,\n",
    "                                                max_evals=250,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/models_fe0_xgbmv_fr_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(models_fe0_xgbmv_fr_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('../models/params_fe0_xgbmv_fr_l.pickle', 'wb') as handle:\n",
    "#     pickle.dump(params_fe0_xgbmv_fr_l, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# post-training (pickle of models exists)\n",
    "with open('../models/models_fe0_xgbmv_fr_l.pickle', 'rb') as handle:\n",
    "    models_fe0_xgbmv_fr_l = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = 9.156463285480921, mae = 7.336900121103496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>C=C</th>\n",
       "      <th>C#C</th>\n",
       "      <th>Ar</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>...</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>M</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>molecule</th>\n",
       "      <th>density</th>\n",
       "      <th>mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.288</td>\n",
       "      <td>30.3</td>\n",
       "      <td>Dibutyl maleate</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>229.112806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.095</td>\n",
       "      <td>45.2</td>\n",
       "      <td>Trimethylene glycol</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>72.271821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.339</td>\n",
       "      <td>25.4</td>\n",
       "      <td>Dihexyl ether</td>\n",
       "      <td>0.7936</td>\n",
       "      <td>234.802167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.124</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Benzaldehyde</td>\n",
       "      <td>1.0470</td>\n",
       "      <td>101.360076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.242</td>\n",
       "      <td>24.1</td>\n",
       "      <td>2,6-Dimethyl-4-heptanone</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>176.435128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        C     H  C=C  C#C   Ar  O-alc  O-eth  O-ald  O-ket  O-acid  ...   R4  \\\n",
       "241  12.0  20.0  1.0  0.0  0.0    0.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "100   3.0   8.0  0.0  0.0  0.0    2.0    0.0    0.0    0.0     0.0  ...  0.0   \n",
       "125  12.0  26.0  0.0  0.0  0.0    0.0    1.0    0.0    0.0     0.0  ...  0.0   \n",
       "152   7.0   6.0  0.0  0.0  1.0    0.0    0.0    1.0    0.0     0.0  ...  0.0   \n",
       "160   9.0  18.0  0.0  0.0  0.0    0.0    0.0    0.0    1.0     0.0  ...  0.0   \n",
       "\n",
       "      R5   R6   R7   R8        M  measured_st                  molecule  \\\n",
       "241  0.0  0.0  0.0  0.0  228.288         30.3           Dibutyl maleate   \n",
       "100  0.0  0.0  0.0  0.0   76.095         45.2       Trimethylene glycol   \n",
       "125  0.0  0.0  0.0  0.0  186.339         25.4             Dihexyl ether   \n",
       "152  0.0  0.0  0.0  0.0  106.124         38.0              Benzaldehyde   \n",
       "160  0.0  0.0  0.0  0.0  142.242         24.1  2,6-Dimethyl-4-heptanone   \n",
       "\n",
       "     density          mv  \n",
       "241   0.9964  229.112806  \n",
       "100   1.0529   72.271821  \n",
       "125   0.7936  234.802167  \n",
       "152   1.0470  101.360076  \n",
       "160   0.8062  176.435128  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_fe0_xgbmv_fr_ll, mae_fe0_xgbmv_fr_ll, i_out_fe0_xgbmv_fr_ll = evaluate_xgb_models(models_fe0_xgbmv_fr_l,\n",
    "                        X_fe0_test[X_fe0_test.columns.difference(['M', 'mv', 'density'])], \n",
    "                        X_fe0_test['mv'], \n",
    "                        weights=None,\n",
    "                        num_outliers=5, \n",
    "                        title='fe0_xgbmv_fr_ll\\nfragments, train: liquid, test: liquid',\n",
    "                        x_label='predicted molar volume',\n",
    "                        y_label='measured molar volume',\n",
    "                        with_line=True)\n",
    "print(f\"rmse = {rmse_fe0_xgbmv_fr_ll}, mae = {mae_fe0_xgbmv_fr_ll}\")\n",
    "display(df_fe0.loc[i_out_fe0_xgbmv_fr_ll])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - molar volume of polymer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ar</th>\n",
       "      <th>C</th>\n",
       "      <th>C=C</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ester</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>commercial</th>\n",
       "      <th>measured_st</th>\n",
       "      <th>mn</th>\n",
       "      <th>st_disperse</th>\n",
       "      <th>st_polar</th>\n",
       "      <th>tg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.249</td>\n",
       "      <td>7.206</td>\n",
       "      <td>0.149</td>\n",
       "      <td>9.128</td>\n",
       "      <td>145.669296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0</td>\n",
       "      <td>29.77</td>\n",
       "      <td>2500</td>\n",
       "      <td>21.38</td>\n",
       "      <td>8.39</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.248</td>\n",
       "      <td>10.749</td>\n",
       "      <td>0.149</td>\n",
       "      <td>15.212</td>\n",
       "      <td>194.358957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0</td>\n",
       "      <td>33.18</td>\n",
       "      <td>2700</td>\n",
       "      <td>19.33</td>\n",
       "      <td>13.85</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>10.238</td>\n",
       "      <td>0.149</td>\n",
       "      <td>16.178</td>\n",
       "      <td>189.161050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.008</td>\n",
       "      <td>0</td>\n",
       "      <td>34.52</td>\n",
       "      <td>2800</td>\n",
       "      <td>17.85</td>\n",
       "      <td>16.67</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>10.131</td>\n",
       "      <td>0.243</td>\n",
       "      <td>15.776</td>\n",
       "      <td>187.182675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0</td>\n",
       "      <td>46.10</td>\n",
       "      <td>2500</td>\n",
       "      <td>16.19</td>\n",
       "      <td>29.91</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>7.037</td>\n",
       "      <td>0.245</td>\n",
       "      <td>11.620</td>\n",
       "      <td>145.959385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>29.11</td>\n",
       "      <td>2300</td>\n",
       "      <td>24.64</td>\n",
       "      <td>4.47</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ar       C    C=C       H           M  O-acid  O-alc  O-ald  O-ester  \\\n",
       "0  0.249   7.206  0.149   9.128  145.669296     0.0    0.0    0.0    1.988   \n",
       "1  0.248  10.749  0.149  15.212  194.358957     0.0    0.0    0.0    1.984   \n",
       "2  0.000  10.238  0.149  16.178  189.161050     0.0    0.0    0.0    1.984   \n",
       "3  0.000  10.131  0.243  15.776  187.182675     0.0    0.0    0.0    1.948   \n",
       "4  0.000   7.037  0.245  11.620  145.959385     0.0    0.0    0.0    1.964   \n",
       "\n",
       "   O-eth  O-ket   R5     R6  commercial  measured_st    mn  st_disperse  \\\n",
       "0    0.0    0.0  0.0  0.503           0        29.77  2500        21.38   \n",
       "1    0.0    0.0  0.0  1.010           0        33.18  2700        19.33   \n",
       "2    0.0    0.0  0.0  1.008           0        34.52  2800        17.85   \n",
       "3    0.0    0.0  0.0  1.026           0        46.10  2500        16.19   \n",
       "4    0.0    0.0  0.0  0.000           0        29.11  2300        24.64   \n",
       "\n",
       "   st_polar  tg  \n",
       "0      8.39  17  \n",
       "1     13.85  94  \n",
       "2     16.67  55  \n",
       "3     29.91  70  \n",
       "4      4.47 -26  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_fe0 = pd.read_csv('../data/df_test_fe0.csv', index_col=0)\n",
    "df_test_fe0_clean = df_test_fe0.loc[df_test_fe0[features_excluded].sum(axis=1) == 0, \n",
    "                                    df_test_fe0.columns.difference(features_excluded)]\n",
    "print(len(df_test_fe0_clean))\n",
    "df_test_fe0_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/fe0_lmmv_fr_l.pickle', 'rb') as handle:\n",
    "    fe0_lmmv_fr_l = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_hat = fe0_lmmv_fr_l.predict(df_test_fe0_clean[df_test_fe0_clean.columns.difference(['M',\n",
    "                                                                              'commercial',\n",
    "                                                                              'measured_st',\n",
    "                                                                              'mn',\n",
    "                                                                              'st_disperse',\n",
    "                                                                              'st_polar',\n",
    "                                                                              'tg'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28bd9311ac8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(mv_hat, df_test_fe0_clean['st_disperse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
