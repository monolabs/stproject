{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../src/stproject')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ar</th>\n",
       "      <th>C</th>\n",
       "      <th>C=C</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O-acid</th>\n",
       "      <th>O-alc</th>\n",
       "      <th>O-ald</th>\n",
       "      <th>O-ester</th>\n",
       "      <th>O-eth</th>\n",
       "      <th>O-ket</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>74.079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>106.121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>116.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>134.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>116.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>74.123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>150.174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>134.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ar     C  C=C     H        M  O-acid  O-alc  O-ald  O-ester  O-eth  \\\n",
       "188  0.0   3.0  0.0   6.0   74.079     0.0    0.0    0.0      2.0    0.0   \n",
       "183  0.0   5.0  0.0  10.0  102.133     0.0    0.0    0.0      2.0    0.0   \n",
       "102  0.0   4.0  0.0  10.0  106.121     0.0    2.0    0.0      0.0    1.0   \n",
       "185  0.0   6.0  0.0  12.0  116.160     0.0    0.0    0.0      2.0    0.0   \n",
       "63   1.0  10.0  0.0  14.0  134.222     0.0    0.0    0.0      0.0    0.0   \n",
       "..   ...   ...  ...   ...      ...     ...    ...    ...      ...    ...   \n",
       "21   0.0   9.0  0.0  20.0  128.259     0.0    0.0    0.0      0.0    0.0   \n",
       "196  0.0   6.0  0.0  12.0  116.160     0.0    0.0    0.0      2.0    0.0   \n",
       "74   0.0   4.0  0.0  10.0   74.123     0.0    1.0    0.0      0.0    0.0   \n",
       "111  0.0   6.0  0.0  14.0  150.174     0.0    2.0    0.0      0.0    2.0   \n",
       "107  0.0   6.0  0.0  14.0  134.175     0.0    1.0    0.0      0.0    2.0   \n",
       "\n",
       "     O-ket   R5   R6  density  \n",
       "188    0.0  0.0  0.0   0.9342  \n",
       "183    0.0  0.0  0.0   0.8930  \n",
       "102    0.0  0.0  0.0   1.1800  \n",
       "185    0.0  0.0  0.0   0.8853  \n",
       "63     0.0  0.0  0.0   0.8662  \n",
       "..     ...  ...  ...      ...  \n",
       "21     0.0  0.0  0.0   0.7185  \n",
       "196    0.0  0.0  0.0   0.8660  \n",
       "74     0.0  0.0  0.0   0.8096  \n",
       "111    0.0  0.0  0.0   1.1250  \n",
       "107    0.0  0.0  0.0   0.9870  \n",
       "\n",
       "[210 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_excluded = ['C#C', 'R3', 'R4', 'R7', 'R8', 'molecule']\n",
    "X_train, X_valid, y_train, y_valid = load_data_fe0('../data/df_fe0.csv', features_excluded, 'measured_st')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_xgb(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    # watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "    predictions = model.predict(dvalid)\n",
    "    score = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "def optimize_xgb(trials, score_func, algo=tpe.suggest, max_evals=250):\n",
    "\n",
    "    # this function optimizes xgb parameters\n",
    "    # trials = hyperopt trials object\n",
    "    # score_xgb = score function\n",
    "    # algo = algorithm use to suggest next point\n",
    "    # returns best parameters\n",
    "\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "             'eta' : hp.quniform('eta', 0.01, 0.10, 0.02),\n",
    "             'max_depth' : hp.choice('max_depth', np.arange(1, 13, 1)),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'eval_metric': 'rmse',\n",
    "             'objective': 'reg:squarederror',\n",
    "             'nthread' : 6,\n",
    "             'silent' : 1,\n",
    "             'seed': 42\n",
    "             }\n",
    "\n",
    "    best = fmin(score_func, space, algo=algo, trials=trials, max_evals=max_evals)\n",
    "    print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'n_estimators': <hyperopt.pyll.base.Apply object at 0x00000221A6450EC8>, 'eta': <hyperopt.pyll.base.Apply object at 0x00000221A6109B88>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x00000221A645C0C8>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x00000221A645CBC8>, 'subsample': <hyperopt.pyll.base.Apply object at 0x00000221A645CE88>, 'gamma': <hyperopt.pyll.base.Apply object at 0x00000221A6461C48>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x00000221A6461808>, 'eval_metric': 'rmse', 'objective': 'reg:squarederror', 'nthread': 6, 'silent': 1, 'seed': 42}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'Apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3fa836dbb67d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Trials object where the history of search will be stored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moptimize_xgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-4c1fa4e006d2>\u001b[0m in \u001b[0;36moptimize_xgb\u001b[1;34m(trials, score_func, algo, max_evals)\u001b[0m\n\u001b[0;32m     36\u001b[0m              }\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-4c1fa4e006d2>\u001b[0m in \u001b[0;36mscore_xgb\u001b[1;34m(params, X_train, X_valid, y_train, y_valid)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training with params : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'Apply'"
     ]
    }
   ],
   "source": [
    "# Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "optimize_xgb(trials, score_xgb, max_evals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best rmse of 1.421 achieved with colsample_by_tree: 0.55, eta: 0.06, gamma: 0.80, max_depth: 2, min_child_weight: 2.0, n_estimators: 102, subsample: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with best params\n",
    "xgb_best = xgb.XGBRegressor(n_estimators=102,\n",
    "                            learning_rate=0.06,\n",
    "                            max_depth=2,\n",
    "                            min_child_weight=2,\n",
    "                            subsample=0.5,\n",
    "                            gamma=0.8,\n",
    "                            colsample_by_tree=0.55,\n",
    "                            objective='reg:squarederror',\n",
    "                            n_jobs=6,\n",
    "                            verbosity=3,\n",
    "                           random_state=42)\n",
    "xgb_best.fit(X_train, y_train, early_stopping_rounds=25, eval_set=[(X_valid, y_valid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances\n",
    "plt.barh(X_train.columns, xgb_best.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(30, 30))\n",
    "# plot_tree(xgb_best, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rmse = {np.sqrt(np.mean((xgb_best.predict(X_valid)-y_valid)**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'y_hat': xgb_best.predict(X_valid), 'y': y_valid})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs by priority:\n",
    "\n",
    "0. try features scaled by molecular weight, molecular fragments only\n",
    "1. do the same with multiple train-test(valid) splitting + weighted prediction\n",
    "2. use triple split: train, valid, test with test set matching the literature data df_stliq_clean was taken from\n",
    "3. test each final model against feature-engineered polymer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB with train, valid, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fe0_2(features_excluded, target):\n",
    "    df_ref = pd.read_csv('../data/df_stliq_clean.csv', index_col=0)\n",
    "    df = pd.read_csv('../data/df_fe0.csv', index_col=0)\n",
    "    df = df[df[features_excluded].sum(axis=1) == 0]\n",
    "    \n",
    "    # pulling index of test data from ref (original_id column contains 'Test')\n",
    "    test_idx = df_ref[df_ref['original_id'].str.contains('Test')].index.tolist()\n",
    "    df_train = df[~df.index.isin(test_idx)]\n",
    "    df_test = df[df.index.isin(test_idx)]\n",
    "    X_train = df_train[df_train.columns.difference(features_excluded + [target])]\n",
    "    y_train = df_train[target]\n",
    "    X_test = df_test[df_test.columns.difference(features_excluded + [target])]\n",
    "    y_test = df_test[target]\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = \\\n",
    "load_data_fe0_2(features_excluded, 'measured_st')\n",
    "len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials2 = Trials()\n",
    "# optimize(trials2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best rmse of 1.526 achieved with colsample_by_tree: 0.95, eta: 0.06, gamma: 0.5, max_depth: 6, min_child_weight: 4.0, n_estimators: 248, subsample: 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check index consistency with 'append'\n",
    "print(all(X_train.append(X_valid).index == y_train.append(y_valid).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with best params\n",
    "xgb_best2_1 = xgb.XGBRegressor(n_estimators=248,\n",
    "                            learning_rate=0.06,\n",
    "                            max_depth=6,\n",
    "                            min_child_weight=4,\n",
    "                            subsample=0.85,\n",
    "                            gamma=0.5,\n",
    "                            colsample_by_tree=0.95,\n",
    "                            objective='reg:squarederror',\n",
    "                            n_jobs=6,\n",
    "                            verbosity=3,\n",
    "                            random_state=42)\n",
    "xgb_best2_1.fit(X_train.append(X_valid), y_train.append(y_valid), eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances\n",
    "plt.barh(X_train.columns, xgb_best2_1.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rmse of XGB with fe0 + full features  = {np.sqrt(mean_squared_error(y_test, xgb_best2_1.predict(X_test)))}\")\n",
    "sns.scatterplot(xgb_best2_1.predict(X_test), y_test)\n",
    "sns.lineplot(x=[17, 50], y=[15, 47], alpha=0.2)\n",
    "plt.xlabel('predicted surface tension')\n",
    "plt.ylabel('measured surface tension')\n",
    "plt.title('XGB fe0 - full features', {'fontsize': 15, 'weight': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragments only (scaled by molecular weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_M(df):\n",
    "    # df contains all numeric features\n",
    "    # this function drops 'density' feature and normalizes the molecular fragments by molecular weight\n",
    "    return df[df.columns.difference(['density', 'M'])].divide(df['M'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scale_M(X_train)\n",
    "X_valid = scale_M(X_valid)\n",
    "X_test = scale_M(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials3 = Trials()\n",
    "optimize(trials3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with best params\n",
    "xgb_best3 = xgb.XGBRegressor(n_estimators=472,\n",
    "                            learning_rate=0.08,\n",
    "                            max_depth=4,\n",
    "                            min_child_weight=1,\n",
    "                            subsample=0.5,\n",
    "                            gamma=1,\n",
    "                            colsample_by_tree=1,\n",
    "                            objective='reg:squarederror',\n",
    "                            n_jobs=6,\n",
    "                            verbosity=3,\n",
    "                            random_state=42)\n",
    "xgb_best3.fit(X_train.append(X_valid), y_train.append(y_valid), early_stopping_rounds=25, eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances\n",
    "plt.barh(X_train.columns, xgb_best3.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rmse of XGB with fe0 + features/M  = {np.sqrt(mean_squared_error(y_test, xgb_best3.predict(X_test)))}\")\n",
    "sns.scatterplot(xgb_best3.predict(X_test), y_test)\n",
    "sns.lineplot(x=[17, 50], y=[15, 47], alpha=0.2)\n",
    "plt.xlabel('predicted surface tension')\n",
    "plt.ylabel('measured surface tension')\n",
    "plt.title('XGB fe0 - features/M', {'fontsize': 15, 'weight': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragments only (scaled by density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_density(df):\n",
    "    # df contains all numeric features\n",
    "    # this function drops 'density' feature and normalizes the molecular fragments by molecular weight\n",
    "    return df[df.columns.difference(['density', 'M'])].divide(df['density'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scale_density(X_train)\n",
    "X_valid = scale_density(X_valid)\n",
    "X_test = scale_density(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials4 = Trials()\n",
    "optimize(trials4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/polyesters.csv')\n",
    "df_diols_fe1 = pd.read_csv('../data/df_diols_fe1.csv', index_col=0)\n",
    "df_acids_fe1 = pd.read_csv('../data/df_acids_fe1.csv', index_col=0)\n",
    "\n",
    "# correcting 'O-alc', 'O-acid' and 'O-ester' by subtracting atom/functional group loss from condensation\n",
    "df_diols_fe1['OH'] -= 2\n",
    "df_acids_fe1['COOH'] -= 2\n",
    "df_acids_fe1['COOR'] += 2\n",
    "\n",
    "df_monomers_fe1 = pd.concat([df_diols_fe1, df_acids_fe1])\n",
    "df_monomers_fe1\n",
    "\n",
    "monomers = df_test.columns[df_test.columns.str.contains('diol|acid')]\n",
    "features = df_monomers_fe1.columns\n",
    "\n",
    "df_test_fe1 = avg_monomer_features(df_test, df_monomers_fe1, monomers, features)\n",
    "st_test = df_test['measured_st']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3 = (df_test_fe1[df_test_fe1.columns.difference(['M']+features_excluded)]\n",
    "           .divide(df_test_fe1['M']-18, axis=0))\n",
    "y_hat_test3 = xgb_best3.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_hat_test3, st_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rmse = {np.sqrt(np.mean((y_hat_test3-st_test)**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
